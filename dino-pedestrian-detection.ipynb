{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191},{"sourceId":9459432,"sourceType":"datasetVersion","datasetId":5750694},{"sourceId":9469335,"sourceType":"datasetVersion","datasetId":5758267},{"sourceId":119328,"sourceType":"modelInstanceVersion","modelInstanceId":100347,"modelId":124515}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Necessary Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport torch\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport cv2\nimport json\nimport random\n\n\n# Set plot style for Seaborn\nsns.set(style=\"darkgrid\")\n\n# Set the display options for pandas\npd.set_option('display.max_colwidth', 200)\npd.set_option('display.max_rows', None)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T12:07:42.734676Z","iopub.execute_input":"2024-09-24T12:07:42.735078Z","iopub.status.idle":"2024-09-24T12:07:42.742524Z","shell.execute_reply.started":"2024-09-24T12:07:42.735042Z","shell.execute_reply":"2024-09-24T12:07:42.741435Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"markdown","source":"## Clean Working Directory","metadata":{}},{"cell_type":"code","source":"\n# Path to the working directory\nworking_dir = \"/kaggle/working/\"\n\n# Remove all files and subdirectories\ntry:\n    shutil.rmtree(working_dir)\n    os.makedirs(working_dir)  # Recreate the directory if needed\n    print(f\"Cleared the working directory: {working_dir}\")\nexcept Exception as e:\n    print(f\"Error clearing working directory: {e}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-24T06:15:20.189309Z","iopub.execute_input":"2024-09-24T06:15:20.190955Z","iopub.status.idle":"2024-09-24T06:15:20.210812Z","shell.execute_reply.started":"2024-09-24T06:15:20.190852Z","shell.execute_reply":"2024-09-24T06:15:20.208813Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Error clearing working directory: [Errno 16] Device or resource busy: '/kaggle/working/'\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the paths to the directories\ndirectories_to_delete = [\n    '/kaggle/working/PEDESTRIAN'\n]\n\n# Loop through the list of directories and delete them if they exist\nfor dir_path in directories_to_delete:\n    if os.path.exists(dir_path):\n        shutil.rmtree(dir_path)  # Use shutil.rmtree to remove the directory and its contents\n        print(f\"{dir_path} has been deleted.\")\n    else:\n        print(f\"{dir_path} does not exist.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T07:51:43.126669Z","iopub.execute_input":"2024-09-24T07:51:43.127233Z","iopub.status.idle":"2024-09-24T07:51:43.146193Z","shell.execute_reply.started":"2024-09-24T07:51:43.127179Z","shell.execute_reply":"2024-09-24T07:51:43.145351Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"/kaggle/working/PEDESTRIAN has been deleted.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the paths to the files\nfiles_to_delete = [\n    '/kaggle/working/PEDESTRIAN.zip',\n]\n\n# Loop through the list of files and delete them if they exist\nfor file_path in files_to_delete:\n    if os.path.exists(file_path):\n        os.remove(file_path)\n        print(f\"{file_path} has been deleted.\")\n    else:\n        print(f\"{file_path} does not exist.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the device to cuda if available, otherwise cpu\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-09-24T06:15:32.016501Z","iopub.execute_input":"2024-09-24T06:15:32.017407Z","iopub.status.idle":"2024-09-24T06:15:32.054735Z","shell.execute_reply.started":"2024-09-24T06:15:32.017350Z","shell.execute_reply":"2024-09-24T06:15:32.053449Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"# Paths\nimages_path = \"/kaggle/input/pedestrian-iit-delhi/Dataset_for_CV_intern_Assignment/Pedestrian_dataset_for_internship_assignment/Pedestrian_dataset_for_internship_assignment\"\nannotations_path = \"/kaggle/input/pedestrian-iit-delhi/Dataset_for_CV_intern_Assignment/random_sample_mavi_2_gt.json\"","metadata":{"execution":{"iopub.status.busy":"2024-09-24T06:15:33.891568Z","iopub.execute_input":"2024-09-24T06:15:33.892599Z","iopub.status.idle":"2024-09-24T06:15:33.896862Z","shell.execute_reply.started":"2024-09-24T06:15:33.892556Z","shell.execute_reply":"2024-09-24T06:15:33.895798Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Open the JSON file\nwith open(annotations_path, 'r') as file:\n    data = json.load(file) ","metadata":{"execution":{"iopub.status.busy":"2024-09-24T08:36:02.066536Z","iopub.execute_input":"2024-09-24T08:36:02.066962Z","iopub.status.idle":"2024-09-24T08:36:02.086836Z","shell.execute_reply.started":"2024-09-24T08:36:02.066922Z","shell.execute_reply":"2024-09-24T08:36:02.085847Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"data.keys()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T08:36:04.211806Z","iopub.execute_input":"2024-09-24T08:36:04.212211Z","iopub.status.idle":"2024-09-24T08:36:04.218552Z","shell.execute_reply.started":"2024-09-24T08:36:04.212170Z","shell.execute_reply":"2024-09-24T08:36:04.217601Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"dict_keys(['images', 'annotations', 'categories'])"},"metadata":{}}]},{"cell_type":"code","source":"data['images'][0]","metadata":{"execution":{"iopub.status.busy":"2024-09-24T08:36:06.216991Z","iopub.execute_input":"2024-09-24T08:36:06.217715Z","iopub.status.idle":"2024-09-24T08:36:06.224654Z","shell.execute_reply.started":"2024-09-24T08:36:06.217654Z","shell.execute_reply":"2024-09-24T08:36:06.223591Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"{'height': 480, 'width': 640, 'id': 1, 'file_name': '1229.jpg'}"},"metadata":{}}]},{"cell_type":"code","source":"data['annotations'][0]","metadata":{"execution":{"iopub.status.busy":"2024-09-24T06:16:04.626476Z","iopub.execute_input":"2024-09-24T06:16:04.627217Z","iopub.status.idle":"2024-09-24T06:16:04.634103Z","shell.execute_reply.started":"2024-09-24T06:16:04.627180Z","shell.execute_reply":"2024-09-24T06:16:04.632874Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'iscrowd': 0,\n 'image_id': 1,\n 'bbox': [297, 262, 12, 33],\n 'segmentation': [],\n 'category_id': 1,\n 'id': 1,\n 'area': 396,\n 'ignore': 0,\n 'vis_ratio': 1.0,\n 'height': 33}"},"metadata":{}}]},{"cell_type":"code","source":"data['categories'][0]","metadata":{"execution":{"iopub.status.busy":"2024-09-24T06:16:07.181472Z","iopub.execute_input":"2024-09-24T06:16:07.181878Z","iopub.status.idle":"2024-09-24T06:16:07.187848Z","shell.execute_reply.started":"2024-09-24T06:16:07.181840Z","shell.execute_reply":"2024-09-24T06:16:07.186885Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'id': 1, 'name': 'pedestrian', 'supercategory': 'pedestrian'}"},"metadata":{}}]},{"cell_type":"code","source":"# Pretty print the 'images' section\nif 'images' in data:\n    i=0\n    print(\"\\nImages:\")\n    for image in data['images']:\n        i+=1\n        print(f\"  Image ID: {image['id']}\")\n        print(f\"  File Name: {image['file_name']}\")\n        print(f\"  Dimensions: {image['width']}x{image['height']}\")\n        print()\n    print(f\"Count:\", i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pretty print the 'annotations' section\nif 'annotations' in data:\n    i=0\n    print(\"\\nAnnotations:\")\n    for annotation in data['annotations']:\n        i+=1\n        print(f\"  Image ID: {annotation['image_id']}\")\n        print(f\"  Bounding Box: {annotation['bbox']}\")\n        print(f\"  Category ID: {annotation['category_id']}\")\n        print() \n    print(f\"Count:\", i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split dataset into Train and Val sets","metadata":{}},{"cell_type":"code","source":"# Define the paths\noriginal_images_path = \"/kaggle/input/pedestrian-iit-delhi/Dataset_for_CV_intern_Assignment/Pedestrian_dataset_for_internship_assignment/Pedestrian_dataset_for_internship_assignment\"\noriginal_annotations_path = \"/kaggle/input/pedestrian-iit-delhi/Dataset_for_CV_intern_Assignment/random_sample_mavi_2_gt.json\"\noutput_dir = \"/kaggle/working/pedestrian\"\n\n# Create the necessary directories\ntrain_images_dir = os.path.join(output_dir, \"train\")\nval_images_dir = os.path.join(output_dir, \"val\")\nannotations_dir = os.path.join(output_dir, \"annotations\")\n\nos.makedirs(train_images_dir, exist_ok=True)\nos.makedirs(val_images_dir, exist_ok=True)\nos.makedirs(annotations_dir, exist_ok=True)\n\n# Load the original annotations\nwith open(original_annotations_path, 'r') as file:\n    data = json.load(file)\n\n# Get the list of images\nimages = data['images']\nrandom.shuffle(images)  # Shuffle the images to split randomly\n\n# Split images into training and validation sets\ntrain_images = images[:160]\nval_images = images[160:200]\n\n# Create a mapping from image_id to file_name for quick access\nimage_id_to_file = {img['id']: img['file_name'] for img in images}\n\n# Prepare the annotation data for train and val\ntrain_annotations = []\nval_annotations = []\n\nfor annotation in data['annotations']:\n    if annotation['image_id'] in [img['id'] for img in train_images]:\n        train_annotations.append(annotation)\n    elif annotation['image_id'] in [img['id'] for img in val_images]:\n        val_annotations.append(annotation)\n\n# Copy images to train and val folders\nfor img in train_images:\n    src_path = os.path.join(original_images_path, img['file_name'])\n    dst_path = os.path.join(train_images_dir, img['file_name'])\n    shutil.copy(src_path, dst_path)\n\nfor img in val_images:\n    src_path = os.path.join(original_images_path, img['file_name'])\n    dst_path = os.path.join(val_images_dir, img['file_name'])\n    shutil.copy(src_path, dst_path)\n\n# Create the final annotation JSON files\ninstances_train = {\n    'images': train_images,\n    'annotations': train_annotations,\n    'categories': data['categories']\n}\n\ninstances_val = {\n    'images': val_images,\n    'annotations': val_annotations,\n    'categories': data['categories']\n}\n\n# Save the annotations as JSON files\nwith open(os.path.join(annotations_dir, 'instances_train.json'), 'w') as f:\n    json.dump(instances_train, f)\n\nwith open(os.path.join(annotations_dir, 'instances_val.json'), 'w') as f:\n    json.dump(instances_val, f)\n\nprint(\"Dataset has been successfully split and organized!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T07:52:28.439148Z","iopub.execute_input":"2024-09-24T07:52:28.439650Z","iopub.status.idle":"2024-09-24T07:52:28.791819Z","shell.execute_reply.started":"2024-09-24T07:52:28.439611Z","shell.execute_reply":"2024-09-24T07:52:28.790854Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Dataset has been successfully split and organized!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the path to the PEDESTRIAN folder\npedestrian_path = \"/kaggle/working/pedestrian\"\nzip_file_path = \"/kaggle/working/pedestrian.zip\"\n\n# Create a ZIP file of the COCODIR folder\nshutil.make_archive(zip_file_path[:-4], 'zip', pedestrian_path)\n\nprint(\"ZIP file created successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T07:54:17.350831Z","iopub.execute_input":"2024-09-24T07:54:17.351567Z","iopub.status.idle":"2024-09-24T07:54:18.368346Z","shell.execute_reply.started":"2024-09-24T07:54:17.351523Z","shell.execute_reply":"2024-09-24T07:54:18.367409Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"ZIP file created successfully.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Clone DINO repository","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/IDEA-Research/DINO.git","metadata":{"execution":{"iopub.status.busy":"2024-09-24T06:29:17.256879Z","iopub.execute_input":"2024-09-24T06:29:17.257764Z","iopub.status.idle":"2024-09-24T06:29:19.695652Z","shell.execute_reply.started":"2024-09-24T06:29:17.257723Z","shell.execute_reply":"2024-09-24T06:29:19.694432Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Cloning into 'DINO'...\nremote: Enumerating objects: 442, done.\u001b[K\nremote: Counting objects: 100% (191/191), done.\u001b[K\nremote: Compressing objects: 100% (95/95), done.\u001b[K\nremote: Total 442 (delta 136), reused 96 (delta 96), pack-reused 251 (from 1)\u001b[K\nReceiving objects: 100% (442/442), 13.43 MiB | 20.47 MiB/s, done.\nResolving deltas: 100% (191/191), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd DINO","metadata":{"execution":{"iopub.status.busy":"2024-09-24T06:34:34.804696Z","iopub.execute_input":"2024-09-24T06:34:34.805109Z","iopub.status.idle":"2024-09-24T06:34:34.812409Z","shell.execute_reply.started":"2024-09-24T06:34:34.805072Z","shell.execute_reply":"2024-09-24T06:34:34.811432Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"/kaggle/working/DINO\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Setting up the necessary environment and dependencies","metadata":{}},{"cell_type":"code","source":"!conda install -c pytorch pytorch torchvision -y","metadata":{"execution":{"iopub.status.busy":"2024-09-24T06:34:42.682672Z","iopub.execute_input":"2024-09-24T06:34:42.683437Z","iopub.status.idle":"2024-09-24T06:45:03.374161Z","shell.execute_reply.started":"2024-09-24T06:34:42.683368Z","shell.execute_reply":"2024-09-24T06:45:03.372988Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Retrieving notices: ...working... done\nChannels:\n - pytorch\n - rapidsai\n - nvidia\n - nodefaults\n - conda-forge\n - defaults\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - pytorch\n    - torchvision\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    blas-1.0                   |              mkl           1 KB  conda-forge\n    ca-certificates-2024.8.30  |       hbcca054_0         155 KB  conda-forge\n    certifi-2024.8.30          |     pyhd8ed1ab_0         160 KB  conda-forge\n    cuda-cccl-12.4.127         |                0         1.4 MB  nvidia\n    cuda-cudart-12.4.127       |                0         198 KB  nvidia\n    cuda-cudart-dev-12.4.127   |                0         413 KB  nvidia\n    cuda-cupti-12.4.127        |                0        16.4 MB  nvidia\n    cuda-libraries-12.4.0      |                0           2 KB  nvidia\n    cuda-nvrtc-12.4.127        |                0        21.0 MB  nvidia\n    cuda-nvtx-12.4.127         |                0          58 KB  nvidia\n    cuda-opencl-12.4.127       |                0          12 KB  nvidia\n    cuda-runtime-12.4.0        |                0           2 KB  nvidia\n    ffmpeg-4.4.0               |       h6987444_4         9.9 MB  conda-forge\n    filelock-3.16.1            |     pyhd8ed1ab_0          17 KB  conda-forge\n    gmp-6.3.0                  |       hac33072_2         449 KB  conda-forge\n    gmpy2-2.1.5                |  py310he8512ff_2         199 KB  conda-forge\n    gnutls-3.6.13              |       h85f3911_1         2.0 MB  conda-forge\n    lame-3.100                 |    h166bdaf_1003         496 KB  conda-forge\n    libblas-3.9.0              |1_h86c2bf4_netlib         199 KB  conda-forge\n    libcblas-3.9.0             |6_ha36c22a_netlib          51 KB  conda-forge\n    libcublas-12.4.2.65        |                0       308.8 MB  nvidia\n    libcublas-dev-12.4.2.65    |                0          75 KB  nvidia\n    libcufft-11.2.0.44         |                0       190.5 MB  nvidia\n    libcufile-1.9.1.3          |                0         1.0 MB  nvidia\n    libcufile-dev-1.9.1.3      |                0          15 KB  nvidia\n    libcurand-10.3.5.147       |                0        51.8 MB  nvidia\n    libcurand-dev-10.3.5.147   |                0         450 KB  nvidia\n    libcusolver-11.6.0.99      |                0       114.3 MB  nvidia\n    libcusolver-dev-11.6.0.99  |                0          49 KB  nvidia\n    libcusparse-12.3.0.142     |                0       179.6 MB  nvidia\n    libcusparse-dev-12.3.0.142 |                0       179.7 MB  nvidia\n    libgcc-14.1.0              |       h77fa898_1         827 KB  conda-forge\n    libgcc-ng-14.1.0           |       h69a702a_1          51 KB  conda-forge\n    libgomp-14.1.0             |       h77fa898_1         449 KB  conda-forge\n    liblapack-3.9.0            |6_ha36c22a_netlib         2.6 MB  conda-forge\n    libnpp-12.2.5.2            |                0       142.8 MB  nvidia\n    libnvfatbin-12.4.127       |                0         856 KB  nvidia\n    libnvjitlink-12.4.99       |                0        18.2 MB  nvidia\n    libnvjpeg-12.3.1.89        |                0         3.0 MB  nvidia\n    libstdcxx-14.1.0           |       hc0a3c3a_1         3.7 MB  conda-forge\n    libstdcxx-ng-14.1.0        |       h4852527_1          51 KB  conda-forge\n    libvpx-1.11.0              |       h9c3ff4c_3         1.1 MB  conda-forge\n    llvm-openmp-15.0.7         |       h0cdce71_0         3.1 MB  conda-forge\n    mkl-2023.0.0               |   h84fe81f_26648       154.0 MB  conda-forge\n    mpc-1.3.1                  |       h24ddda3_1         114 KB  conda-forge\n    mpfr-4.2.1                 |       h90cbb55_3         620 KB  conda-forge\n    mpmath-1.3.0               |     pyhd8ed1ab_0         428 KB  conda-forge\n    nettle-3.6                 |       he412f7d_0         6.5 MB  conda-forge\n    networkx-3.3               |     pyhd8ed1ab_1         1.1 MB  conda-forge\n    openh264-2.1.1             |       h4ff587b_0         711 KB\n    openssl-3.3.2              |       hb9d3cd8_0         2.8 MB  conda-forge\n    pytorch-2.4.1              |py3.10_cuda12.4_cudnn9.1.0_0        1.34 GB  pytorch\n    pytorch-cuda-12.4          |       hc786d27_6           7 KB  pytorch\n    pytorch-mutex-1.0          |             cuda           3 KB  pytorch\n    sympy-1.13.2               | pypyh2585a3b_103         4.4 MB  conda-forge\n    torchtriton-3.0.0          |            py310       233.4 MB  pytorch\n    torchvision-0.19.1         |      py310_cu124         8.2 MB  pytorch\n    x264-1!161.3030            |       h7f98852_1         2.5 MB  conda-forge\n    ------------------------------------------------------------\n                                           Total:        2.97 GB\n\nThe following NEW packages will be INSTALLED:\n\n  blas               conda-forge/linux-64::blas-1.0-mkl \n  cuda-cccl          nvidia/linux-64::cuda-cccl-12.4.127-0 \n  cuda-cupti         nvidia/linux-64::cuda-cupti-12.4.127-0 \n  cuda-libraries     nvidia/linux-64::cuda-libraries-12.4.0-0 \n  cuda-nvtx          nvidia/linux-64::cuda-nvtx-12.4.127-0 \n  cuda-opencl        nvidia/linux-64::cuda-opencl-12.4.127-0 \n  cuda-runtime       nvidia/linux-64::cuda-runtime-12.4.0-0 \n  ffmpeg             conda-forge/linux-64::ffmpeg-4.4.0-h6987444_4 \n  filelock           conda-forge/noarch::filelock-3.16.1-pyhd8ed1ab_0 \n  gmp                conda-forge/linux-64::gmp-6.3.0-hac33072_2 \n  gmpy2              conda-forge/linux-64::gmpy2-2.1.5-py310he8512ff_2 \n  gnutls             conda-forge/linux-64::gnutls-3.6.13-h85f3911_1 \n  lame               conda-forge/linux-64::lame-3.100-h166bdaf_1003 \n  libgcc             conda-forge/linux-64::libgcc-14.1.0-h77fa898_1 \n  libnpp             nvidia/linux-64::libnpp-12.2.5.2-0 \n  libnvfatbin        nvidia/linux-64::libnvfatbin-12.4.127-0 \n  libnvjpeg          nvidia/linux-64::libnvjpeg-12.3.1.89-0 \n  libstdcxx          conda-forge/linux-64::libstdcxx-14.1.0-hc0a3c3a_1 \n  libvpx             conda-forge/linux-64::libvpx-1.11.0-h9c3ff4c_3 \n  mpc                conda-forge/linux-64::mpc-1.3.1-h24ddda3_1 \n  mpfr               conda-forge/linux-64::mpfr-4.2.1-h90cbb55_3 \n  mpmath             conda-forge/noarch::mpmath-1.3.0-pyhd8ed1ab_0 \n  nettle             conda-forge/linux-64::nettle-3.6-he412f7d_0 \n  networkx           conda-forge/noarch::networkx-3.3-pyhd8ed1ab_1 \n  openh264           pkgs/main/linux-64::openh264-2.1.1-h4ff587b_0 \n  pytorch            pytorch/linux-64::pytorch-2.4.1-py3.10_cuda12.4_cudnn9.1.0_0 \n  pytorch-cuda       pytorch/linux-64::pytorch-cuda-12.4-hc786d27_6 \n  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cuda \n  sympy              conda-forge/noarch::sympy-1.13.2-pypyh2585a3b_103 \n  torchtriton        pytorch/linux-64::torchtriton-3.0.0-py310 \n  torchvision        pytorch/linux-64::torchvision-0.19.1-py310_cu124 \n  x264               conda-forge/linux-64::x264-1!161.3030-h7f98852_1 \n\nThe following packages will be UPDATED:\n\n  ca-certificates                       2024.7.4-hbcca054_0 --> 2024.8.30-hbcca054_0 \n  certifi                             2024.7.4-pyhd8ed1ab_0 --> 2024.8.30-pyhd8ed1ab_0 \n  cuda-cudart        conda-forge::cuda-cudart-12.3.101-hd3~ --> nvidia::cuda-cudart-12.4.127-0 \n  cuda-cudart-dev    conda-forge::cuda-cudart-dev-12.3.101~ --> nvidia::cuda-cudart-dev-12.4.127-0 \n  cuda-nvrtc         conda-forge::cuda-nvrtc-12.3.107-hd3a~ --> nvidia::cuda-nvrtc-12.4.127-0 \n  libcublas          conda-forge::libcublas-12.3.4.1-hd3ae~ --> nvidia::libcublas-12.4.2.65-0 \n  libcublas-dev      conda-forge::libcublas-dev-12.3.4.1-h~ --> nvidia::libcublas-dev-12.4.2.65-0 \n  libcufft           conda-forge::libcufft-11.0.12.1-hd3ae~ --> nvidia::libcufft-11.2.0.44-0 \n  libcufile          conda-forge::libcufile-1.8.1.2-hd3aeb~ --> nvidia::libcufile-1.9.1.3-0 \n  libcufile-dev      conda-forge::libcufile-dev-1.8.1.2-hd~ --> nvidia::libcufile-dev-1.9.1.3-0 \n  libcurand          conda-forge::libcurand-10.3.4.107-hd3~ --> nvidia::libcurand-10.3.5.147-0 \n  libcurand-dev      conda-forge::libcurand-dev-10.3.4.107~ --> nvidia::libcurand-dev-10.3.5.147-0 \n  libcusolver        conda-forge::libcusolver-11.5.4.101-h~ --> nvidia::libcusolver-11.6.0.99-0 \n  libcusolver-dev    conda-forge::libcusolver-dev-11.5.4.1~ --> nvidia::libcusolver-dev-11.6.0.99-0 \n  libcusparse        conda-forge::libcusparse-12.2.0.103-h~ --> nvidia::libcusparse-12.3.0.142-0 \n  libcusparse-dev    conda-forge::libcusparse-dev-12.2.0.1~ --> nvidia::libcusparse-dev-12.3.0.142-0 \n  libgcc-ng                               13.2.0-h77fa898_8 --> 14.1.0-h69a702a_1 \n  libgomp                                 13.2.0-h77fa898_8 --> 14.1.0-h77fa898_1 \n  libnvjitlink       conda-forge::libnvjitlink-12.3.101-hd~ --> nvidia::libnvjitlink-12.4.99-0 \n  libstdcxx-ng                            13.2.0-hc0a3c3a_8 --> 14.1.0-h4852527_1 \n  openssl                                  3.3.1-h4bc722e_2 --> 3.3.2-hb9d3cd8_0 \n\nThe following packages will be DOWNGRADED:\n\n  libblas                         3.9.0-23_linux64_openblas --> 3.9.0-1_h86c2bf4_netlib \n  libcblas                        3.9.0-23_linux64_openblas --> 3.9.0-6_ha36c22a_netlib \n  liblapack                       3.9.0-23_linux64_openblas --> 3.9.0-6_ha36c22a_netlib \n  llvm-openmp                             18.1.8-hf5423f3_1 --> 15.0.7-h0cdce71_0 \n  mkl                                 2024.2.1-ha957f24_103 --> 2023.0.0-h84fe81f_26648 \n\n\n\nDownloading and Extracting Packages:\npytorch-2.4.1        | 1.34 GB   |                                       |   0% \nlibcublas-12.4.2.65  | 308.8 MB  |                                       |   0% \u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  |                                       |   0% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nlibcusolver-11.6.0.9 | 114.3 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\nlibcurand-10.3.5.147 | 51.8 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\ncuda-nvrtc-12.4.127  | 21.0 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nlibnvjitlink-12.4.99 | 18.2 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\ncuda-cupti-12.4.127  | 16.4 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\nffmpeg-4.4.0         | 9.9 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\ntorchvision-0.19.1   | 8.2 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnettle-3.6           | 6.5 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsympy-1.13.2         | 4.4 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibstdcxx-14.1.0     | 3.7 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nllvm-openmp-15.0.7   | 3.1 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibnvjpeg-12.3.1.89  | 3.0 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nopenssl-3.3.2        | 2.8 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nliblapack-3.9.0      | 2.6 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx264-1!161.3030      | 2.5 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  |                                       |   0% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   |                                       |   0% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | 3                                     |   1% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   |                                       |   0% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | 4                                     |   1% \u001b[A\u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | 5                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | 6                                     |   2% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | 1                                     |   0% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | 9                                     |   3% \u001b[A\u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #                                     |   3% \u001b[A\u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | 9                                     |   3% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | 2                                     |   1% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #3                                    |   4% \u001b[A\u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #5                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #3                                    |   4% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | 2                                     |   1% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #7                                    |   5% \u001b[A\u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ##1                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #7                                    |   5% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | 3                                     |   1% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ##3                                   |   6% \u001b[A\u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ##6                                   |   7% \u001b[A\u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ##                                    |   6% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | 4                                     |   1% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ##8                                   |   8% \u001b[A\u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ###                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | 5                                     |   1% \u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ###4                                  |   9% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ###1                                  |   8% \u001b[A\u001b[A\n\n\n\npytorch-2.4.1        | 1.34 GB   | 6                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ###9                                  |  11% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ##7                                   |   7% \u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ###5                                  |  10% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ####1                                 |  11% \u001b[A\u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ###                                   |   8% \u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ####4                                 |  12% \u001b[A\u001b[A\u001b[A\n\npytorch-2.4.1        | 1.34 GB   | 6                                     |   2% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ####7                                 |  13% \u001b[A\u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ###4                                  |   9% \u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ####9                                 |  13% \u001b[A\u001b[A\u001b[A\n\npytorch-2.4.1        | 1.34 GB   | 7                                     |   2% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #####2                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\npytorch-2.4.1        | 1.34 GB   | 8                                     |   2% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ####9                                 |  13% \u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ###7                                  |  10% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #####8                                |  16% \u001b[A\u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | #####3                                |  14% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ######                                |  16% \u001b[A\u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | 9                                     |   2% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ######4                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | #####7                                |  16% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ######5                               |  18% \u001b[A\u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | 9                                     |   3% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ######9                               |  19% \u001b[A\u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ######2                               |  17% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #######1                              |  19% \u001b[A\u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | #                                     |   3% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #######4                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #######6                              |  21% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ######6                               |  18% \u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | #1                                    |   3% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ########                              |  22% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ########2                             |  22% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | #######1                              |  19% \u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | #2                                    |   3% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ########6                             |  23% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ########7                             |  24% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | #######5                              |  20% \u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | #2                                    |   4% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #########2                            |  25% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #########3                            |  25% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ########                              |  22% \u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | #3                                    |   4% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #########8                            |  27% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #########9                            |  27% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ########4                             |  23% \u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | #4                                    |   4% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ##########4                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ##########4                           |  28% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ########9                             |  24% \u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | #5                                    |   4% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ###########                           |  30% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ###########                           |  30% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | #########3                            |  25% \u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | #5                                    |   4% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ###########5                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ###########5                          |  31% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #######4                              |  20% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | #6                                    |   5% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ############1                         |  33% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ############                          |  33% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #######7                              |  21% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | #7                                    |   5% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ############7                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ############6                         |  34% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ########                              |  22% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | #8                                    |   5% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #############3                        |  36% \u001b[A\u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ########4                             |  23% \u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #############1                        |  36% \u001b[A\u001b[A\u001b[A\n\npytorch-2.4.1        | 1.34 GB   | #9                                    |   5% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #############8                        |  38% \u001b[A\u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ########7                             |  24% \u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #############6                        |  37% \u001b[A\u001b[A\u001b[A\n\npytorch-2.4.1        | 1.34 GB   | #9                                    |   5% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ##############4                       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ##############1                       |  38% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #########                             |  25% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ##                                    |   6% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ###############                       |  41% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ##############7                       |  40% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #########4                            |  26% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ##1                                   |   6% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ###############6                      |  42% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ###############2                      |  41% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #########7                            |  26% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ##2                                   |   6% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ################1                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ###############7                      |  43% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ##########1                           |  27% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ##2                                   |   6% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ################7                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ################3                     |  44% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ##########4                           |  28% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ##3                                   |   6% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #################3                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ##########7                           |  29% \u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ################8                     |  46% \u001b[A\u001b[A\u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ##4                                   |   7% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #################9                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #################3                    |  47% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ###########1                          |  30% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ##5                                   |   7% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ##################4                   |  50% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #################9                    |  48% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ###########4                          |  31% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ##5                                   |   7% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ###################                   |  52% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ##################4                   |  50% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ###########8                          |  32% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ##6                                   |   7% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ###################6                  |  53% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ##################9                   |  51% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ############1                         |  33% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ##7                                   |   7% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ####################2                 |  55% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ###################5                  |  53% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ############5                         |  34% \u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ################2                     |  44% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ####################9                 |  57% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ####################1                 |  55% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ############9                         |  35% \u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ################7                     |  45% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #####################6                |  58% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\npytorch-2.4.1        | 1.34 GB   | ##8                                   |   8% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #############3                        |  36% \u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | #################2                    |  47% \u001b[A\u001b[A\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##8                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #####################3                |  58% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | #################7                    |  48% \u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #############6                        |  37% \u001b[A\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##9                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #####################8                |  59% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ##################1                   |  49% \u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ##############                        |  38% \u001b[A\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ######################4               |  61% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ##################6                   |  50% \u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ###1                                  |   8% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ########################              |  65% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #######################               |  62% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ###################                   |  52% \u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ###1                                  |   9% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ########################6             |  67% \u001b[A\u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ###################5                  |  53% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #######################5              |  64% \u001b[A\u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ###2                                  |   9% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #########################2            |  68% \u001b[A\u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ###################9                  |  54% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ########################              |  65% \u001b[A\u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ###3                                  |   9% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #########################7            |  70% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ########################6             |  67% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ####################4                 |  55% \u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ###4                                  |   9% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ##########################3           |  71% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #########################1            |  68% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ####################8                 |  56% \u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ###4                                  |   9% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ##########################8           |  73% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #########################6            |  69% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | #####################2                |  58% \u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ###5                                  |  10% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ###########################4          |  74% \u001b[A\u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | #####################7                |  59% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ##########################1           |  71% \u001b[A\u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ###6                                  |  10% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ############################          |  76% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ##########################7           |  72% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ######################1               |  60% \u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ###7                                  |  10% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ############################6         |  77% \u001b[A\u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ######################5               |  61% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ###########################2          |  74% \u001b[A\u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ###7                                  |  10% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #############################1        |  79% \u001b[A\u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | #######################               |  62% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ###########################7          |  75% \u001b[A\u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ###8                                  |  10% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #############################7        |  80% \u001b[A\u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | #######################4              |  63% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ############################2         |  76% \u001b[A\u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ###9                                  |  11% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ##############################2       |  82% \u001b[A\u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | #######################9              |  65% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ############################8         |  78% \u001b[A\u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ####                                  |  11% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ##############################8       |  83% \u001b[A\u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ########################3             |  66% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #############################3        |  79% \u001b[A\u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ####                                  |  11% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ###############################3      |  85% \u001b[A\u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ########################8             |  67% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #############################8        |  81% \u001b[A\u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ####1                                 |  11% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ###############################9      |  86% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ##############################4       |  82% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | #########################2            |  68% \u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ####2                                 |  11% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ################################5     |  88% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ##############################9       |  84% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ###################6                  |  53% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ####2                                 |  12% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #################################     |  89% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ###############################4      |  85% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ####################                  |  54% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ####3                                 |  12% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | #################################6    |  91% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ################################      |  87% \u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ##########################5           |  72% \u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ####4                                 |  12% \u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ##################################1   |  92% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ################################5     |  88% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ####################6                 |  56% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ####5                                 |  12% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ##################################6   |  94% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #################################     |  89% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #####################                 |  57% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ####5                                 |  12% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ###################################1  |  95% \u001b[A\u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #####################3                |  58% \u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | #################################5    |  91% \u001b[A\u001b[A\u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ####6                                 |  13% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ###################################8  |  97% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ##################################    |  92% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #####################6                |  58% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ####7                                 |  13% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ####################################4 |  98% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ##################################5   |  93% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #####################9                |  59% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ####8                                 |  13% \u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ####################################9 | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ###################################1  |  95% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ######################2               |  60% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ####8                                 |  13% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ###################################7  |  97% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ######################6               |  61% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ####9                                 |  13% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ####################################2 |  98% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #######################               |  62% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | #####                                 |  14% \u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ####################################7 |  99% \u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #######################3              |  63% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | #####1                                |  14% \u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #######################7              |  64% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | #####2                                |  14% \u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ########################1             |  65% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | #####3                                |  14% \u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ########################6             |  67% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | #####4                                |  15% \u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #########################             |  68% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | #####5                                |  15% \u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #########################5            |  69% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | #####6                                |  15% \u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | #########################9            |  70% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | #####7                                |  15% \u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ##########################4           |  71% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | #####8                                |  16% \u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ##########################9           |  73% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | #####9                                |  16% \u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ###########################3          |  74% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ######                                |  16% \u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ###########################8          |  75% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ######1                               |  17% \u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ############################2         |  76% \u001b[A\n\npytorch-2.4.1        | 1.34 GB   | ######2                               |  17% \u001b[A\u001b[A\npytorch-2.4.1        | 1.34 GB   | ######3                               |  17% \u001b[A\npytorch-2.4.1        | 1.34 GB   | ######4                               |  18% \u001b[A\npytorch-2.4.1        | 1.34 GB   | ######6                               |  18% \u001b[A\npytorch-2.4.1        | 1.34 GB   | ######7                               |  18% \u001b[A\npytorch-2.4.1        | 1.34 GB   | ######8                               |  19% \u001b[A\npytorch-2.4.1        | 1.34 GB   | ######9                               |  19% \u001b[A\npytorch-2.4.1        | 1.34 GB   | #######1                              |  19% \u001b[A\npytorch-2.4.1        | 1.34 GB   | #######2                              |  20% \u001b[A\npytorch-2.4.1        | 1.34 GB   | #######3                              |  20% \u001b[A\npytorch-2.4.1        | 1.34 GB   | #######4                              |  20% \u001b[A\npytorch-2.4.1        | 1.34 GB   | #######6                              |  21% \u001b[A\npytorch-2.4.1        | 1.34 GB   | #######7                              |  21% \u001b[A\npytorch-2.4.1        | 1.34 GB   | #######8                              |  21% \u001b[A\npytorch-2.4.1        | 1.34 GB   | #######9                              |  22% \u001b[A\npytorch-2.4.1        | 1.34 GB   | #########7                            |  26% \u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #########9                            |  27% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | #6                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ##4                                   |   7% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##########1                           |  27% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | 6                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ###2                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | #3                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##########3                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ##                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ####6                                 |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##########4                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | #####2                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##########5                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | #####8                                |  16% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ###9                                  |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ######4                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##########6                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ######9                               |  19% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##########7                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | #######4                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##########8                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | #######9                              |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##########9                           |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ########5                             |  23% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###########                           |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ########9                             |  24% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###########1                          |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | #########6                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###########1                          |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ##########3                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###########2                          |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ##########1                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ##########8                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###########3                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | 5                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ###########4                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ##########8                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###########4                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ###########9                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ###########4                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###########4                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ############3                         |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ############                          |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ##1                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###########5                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ############5                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ##7                                   |   7% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | #############2                        |  36% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###########5                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ###2                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###########6                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | #############6                        |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ###7                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###########7                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ##############1                       |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ####2                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###########7                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ##############6                       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###########8                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ##############9                       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ###############1                      |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | #####3                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###########8                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ###############6                      |  42% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | #####8                                |  16% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###########9                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ######3                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ################                      |  43% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###########9                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ################5                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ######8                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############                          |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | #################                     |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | #######3                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############                          |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | #################5                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | #######8                              |  21% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | #################3                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############1                         |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ########2                             |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | #################7                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############1                         |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ########7                             |  24% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############2                         |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | #########2                            |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ###################                   |  51% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ##################5                   |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############2                         |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ###################5                  |  53% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############3                         |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ##########2                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ####################                  |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############3                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ##########6                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ####################4                 |  55% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ###################8                  |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############4                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ####################9                 |  57% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ####################1                 |  55% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############4                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | #####################4                |  58% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ####################5                 |  56% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############5                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | #####################9                |  59% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ####################9                 |  57% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############6                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ######################4               |  61% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | #############1                        |  36% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############6                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ######################9               |  62% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | #############6                        |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############7                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | #######################4              |  63% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ##############2                       |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############7                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | #######################8              |  65% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ##############7                       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############8                         |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ########################3             |  66% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ######################8               |  62% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############8                         |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ########################7             |  67% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ###############7                      |  42% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############9                         |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | #########################2            |  68% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ################2                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ############9                         |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | #########################6            |  69% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############                         |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ########################              |  65% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ##########################1           |  71% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############                         |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ########################3             |  66% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ##########################5           |  72% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ########################7             |  67% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############1                        |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ###########################           |  73% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | #########################2            |  68% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############1                        |  36% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ###########################4          |  74% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | #########################6            |  69% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############2                        |  36% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ###########################9          |  75% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ##########################            |  70% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############2                        |  36% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ############################5         |  77% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ##########################6           |  72% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############3                        |  36% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | #############################         |  78% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ####################4                 |  55% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############3                        |  36% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | #############################5        |  80% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############4                        |  36% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ##############################        |  81% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ####################9                 |  57% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ############################2         |  76% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############4                        |  36% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | #####################5                |  58% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ############################7         |  78% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############5                        |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ######################                |  60% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############5                        |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ###############################8      |  86% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############6                        |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | #############################6        |  80% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | #######################1              |  62% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############6                        |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | #######################5              |  64% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############7                        |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ##############################        |  81% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ########################              |  65% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | #################################2    |  90% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############7                        |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | #################################8    |  91% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############8                        |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ##############################9       |  84% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ##################################5   |  93% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############8                        |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ###############################3      |  85% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | #########################5            |  69% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############9                        |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ###############################6      |  86% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | #########################9            |  70% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #############9                        |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ################################      |  87% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############                        |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ################################4     |  88% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ####################################  |  97% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nlibcusolver-11.6.0.9 | 114.3 MB  |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############                        |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ################################8     |  89% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nlibcusolver-11.6.0.9 | 114.3 MB  | 7                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ####################################5 |  99% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############1                       |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | #################################2    |  90% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nlibcusolver-11.6.0.9 | 114.3 MB  | #4                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ####################################9 | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############1                       |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | #################################6    |  91% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nlibcusolver-11.6.0.9 | 114.3 MB  | ##3                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############2                       |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ##################################2   |  93% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nlibcusolver-11.6.0.9 | 114.3 MB  | ###                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############2                       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ##################################9   |  94% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nlibcusolver-11.6.0.9 | 114.3 MB  | ###7                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############3                       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ###################################4  |  96% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ##############################1       |  82% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############4                       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ###################################8  |  97% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ###############################2      |  84% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############4                       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ####################################3 |  98% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nlibcusolver-11.6.0.9 | 114.3 MB  | #####5                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ###############################8      |  86% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############5                       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nlibcusolver-11.6.0.9 | 114.3 MB  | ######2                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############5                       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nlibcusolver-11.6.0.9 | 114.3 MB  | ######8                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############6                       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nlibcusolver-11.6.0.9 | 114.3 MB  | #######4                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############6                       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nlibcusolver-11.6.0.9 | 114.3 MB  | ########1                             |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############7                       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############8                       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ###################################2  |  95% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############9                       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ###################################9  |  97% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##############9                       |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ####################################6 |  99% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###############                       |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###############1                      |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###############2                      |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###############2                      |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###############3                      |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###############4                      |  42% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###############4                      |  42% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###############5                      |  42% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###############6                      |  42% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###############6                      |  42% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###############7                      |  43% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###############8                      |  43% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###############8                      |  43% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###############9                      |  43% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ################                      |  43% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ################                      |  43% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ################1                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ################2                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ################2                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ################3                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ################3                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ################4                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ################5                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ################5                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ################6                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ################7                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ################8                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ################8                     |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ################9                     |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #################                     |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #################1                    |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nlibcusolver-11.6.0.9 | 114.3 MB  | ####################################1 |  98% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\nlibcurand-10.3.5.147 | 51.8 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #################2                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\nlibcurand-10.3.5.147 | 51.8 MB   | ###3                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #################3                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #################3                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #################4                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #################5                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #################5                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #################6                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #################7                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #################8                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | #################9                    |  49% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##################                    |  49% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##################1                   |  49% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\nlibcurand-10.3.5.147 | 51.8 MB   | ##############################6       |  83% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##################2                   |  49% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nlibnvjitlink-12.4.99 | 18.2 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\nlibcurand-10.3.5.147 | 51.8 MB   | #################################1    |  90% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##################3                   |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nlibnvjitlink-12.4.99 | 18.2 MB   | #######9                              |  21% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\ncuda-nvrtc-12.4.127  | 21.0 MB   | #8                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##################4                   |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\ncuda-nvrtc-12.4.127  | 21.0 MB   | #####6                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nlibnvjitlink-12.4.99 | 18.2 MB   | ###############7                      |  43% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##################4                   |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nlibnvjitlink-12.4.99 | 18.2 MB   | #####################8                |  59% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\ncuda-nvrtc-12.4.127  | 21.0 MB   | ###########7                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##################5                   |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##################6                   |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nlibnvjitlink-12.4.99 | 18.2 MB   | ################################7     |  88% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##################6                   |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##################7                   |  51% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##################7                   |  51% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##################8                   |  51% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##################9                   |  51% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###################                   |  51% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###################1                  |  52% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###################1                  |  52% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###################2                  |  52% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###################3                  |  52% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\ncuda-cupti-12.4.127  | 16.4 MB   | ##########################9           |  73% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###################4                  |  53% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\ntorchvision-0.19.1   | 8.2 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\nffmpeg-4.4.0         | 9.9 MB    | #############                         |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnettle-3.6           | 6.5 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\ncuda-cupti-12.4.127  | 16.4 MB   | #################################8    |  91% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\ntorchvision-0.19.1   | 8.2 MB    | #############6                        |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###################5                  |  53% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\ntorchvision-0.19.1   | 8.2 MB    | ###########################           |  73% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\nffmpeg-4.4.0         | 9.9 MB    | #########################7            |  70% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###################6                  |  53% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###################8                  |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsympy-1.13.2         | 4.4 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibstdcxx-14.1.0     | 3.7 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###################8                  |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsympy-1.13.2         | 4.4 MB    | ####################                  |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibstdcxx-14.1.0     | 3.7 MB    | ################9                     |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nllvm-openmp-15.0.7   | 3.1 MB    | ##################################6   |  94% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ###################9                  |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibstdcxx-14.1.0     | 3.7 MB    | #################################7    |  91% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibnvjpeg-12.3.1.89  | 3.0 MB    | ################################1     |  87% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ####################                  |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nliblapack-3.9.0      | 2.6 MB    | 2                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ####################1                 |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ####################################8 |  99% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\nlibcusparse-dev-12.3 | 179.7 MB  | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\nlibcufft-11.2.0.44   | 190.5 MB  | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\n\n\n\n\nmkl-2023.0.0         | 154.0 MB  | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\ntorchtriton-3.0.0    | 233.4 MB  | ##################################### | 100% \u001b[A\u001b[A\n\n\n\n\n\n\nlibnpp-12.2.5.2      | 142.8 MB  | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nlibnvjitlink-12.4.99 | 18.2 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nlibcusparse-12.3.0.1 | 179.6 MB  | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nlibcublas-12.4.2.65  | 308.8 MB  | ##################################### | 100% \u001b[A\n\n\n\n\n\n\n\n\n\ncuda-nvrtc-12.4.127  | 21.0 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nlibcusolver-11.6.0.9 | 114.3 MB  | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnettle-3.6           | 6.5 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\ntorchvision-0.19.1   | 8.2 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\nffmpeg-4.4.0         | 9.9 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nllvm-openmp-15.0.7   | 3.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\ncuda-cupti-12.4.127  | 16.4 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibnvjpeg-12.3.1.89  | 3.0 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibstdcxx-14.1.0     | 3.7 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nopenssl-3.3.2        | 2.8 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nopenssl-3.3.2        | 2.8 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsympy-1.13.2         | 4.4 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nliblapack-3.9.0      | 2.6 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nliblapack-3.9.0      | 2.6 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx264-1!161.3030      | 2.5 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\npytorch-2.4.1        | 1.34 GB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                                                \n                                                                                \u001b[A\n\n                                                                                \u001b[A\u001b[A\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\u001b[A\n\n\u001b[A\u001b[A\n\n\n\u001b[A\u001b[A\u001b[A\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\u001b[A\n\n\u001b[A\u001b[A\n\n\n\u001b[A\u001b[A\u001b[A\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-09-24T06:47:43.813572Z","iopub.execute_input":"2024-09-24T06:47:43.814050Z","iopub.status.idle":"2024-09-24T06:48:12.292654Z","shell.execute_reply.started":"2024-09-24T06:47:43.814010Z","shell.execute_reply":"2024-09-24T06:48:12.291186Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Collecting pycocotools (from -r requirements.txt (line 2))\n  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-install-vvgrbpvp/pycocotools_482c1cb20c9d48848d349c73008332a7\n  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-install-vvgrbpvp/pycocotools_482c1cb20c9d48848d349c73008332a7\n  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting panopticapi (from -r requirements.txt (line 6))\n  Cloning https://github.com/cocodataset/panopticapi.git to /tmp/pip-install-vvgrbpvp/panopticapi_8550b083170f4e70b72d5ea873d7bc2c\n  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/panopticapi.git /tmp/pip-install-vvgrbpvp/panopticapi_8550b083170f4e70b72d5ea873d7bc2c\n  Resolved https://github.com/cocodataset/panopticapi.git to commit 7bb4655548f98f3fedc07bf37e9040a992b054b0\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (3.0.10)\nCollecting submitit (from -r requirements.txt (line 3))\n  Downloading submitit-1.5.2-py3-none-any.whl.metadata (7.9 kB)\nRequirement already satisfied: torch>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (2.4.0)\nRequirement already satisfied: torchvision>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.19.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.14.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (2.4.0)\nCollecting addict (from -r requirements.txt (line 9))\n  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\nRequirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.40.2)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (1.0.8)\nRequirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools->-r requirements.txt (line 2)) (70.0.0)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools->-r requirements.txt (line 2)) (3.7.5)\nRequirement already satisfied: cloudpickle>=1.2.1 in /opt/conda/lib/python3.10/site-packages (from submitit->-r requirements.txt (line 3)) (3.0.0)\nRequirement already satisfied: typing_extensions>=3.7.4.2 in /opt/conda/lib/python3.10/site-packages (from submitit->-r requirements.txt (line 3)) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->-r requirements.txt (line 4)) (2024.6.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.6.0->-r requirements.txt (line 5)) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.6.0->-r requirements.txt (line 5)) (9.5.0)\nRequirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->-r requirements.txt (line 10)) (7.0.0)\nRequirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->-r requirements.txt (line 10)) (3.11.0)\nRequirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->-r requirements.txt (line 10)) (2.0.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm->-r requirements.txt (line 11)) (6.0.2)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm->-r requirements.txt (line 11)) (0.24.6)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm->-r requirements.txt (line 11)) (0.4.4)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->-r requirements.txt (line 10)) (3.19.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (2.9.0.post0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm->-r requirements.txt (line 11)) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm->-r requirements.txt (line 11)) (4.66.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.5.0->-r requirements.txt (line 4)) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.5.0->-r requirements.txt (line 4)) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 2)) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 11)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 11)) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 11)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 11)) (2024.8.30)\nDownloading submitit-1.5.2-py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m74.9/74.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\nBuilding wheels for collected packages: pycocotools, panopticapi\n  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0-cp310-cp310-linux_x86_64.whl size=101098 sha256=dbbbd2688616326b230a4c307d46b56e44283da81480e48025657ae6c4764561\n  Stored in directory: /tmp/pip-ephem-wheel-cache-u9zvu4d_/wheels/39/61/b4/480fbddb4d3d6bc34083e7397bc6f5d1381f79acc68e9f3511\n  Building wheel for panopticapi (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for panopticapi: filename=panopticapi-0.1-py3-none-any.whl size=8260 sha256=dfd6d017d090ba1ee9bd7e65ae074209100580832f650391d02e676d4780c14c\n  Stored in directory: /tmp/pip-ephem-wheel-cache-u9zvu4d_/wheels/70/87/ae/5c2b138c967549070e3fe35f3b5fcaf1ed56e9f5483a09ee65\nSuccessfully built pycocotools panopticapi\nInstalling collected packages: addict, submitit, panopticapi, pycocotools\nSuccessfully installed addict-2.4.0 panopticapi-0.1 pycocotools-2.0 submitit-1.5.2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Change to the directory\n%cd models/dino/ops","metadata":{"execution":{"iopub.status.busy":"2024-09-24T06:49:26.766156Z","iopub.execute_input":"2024-09-24T06:49:26.767173Z","iopub.status.idle":"2024-09-24T06:49:26.773781Z","shell.execute_reply.started":"2024-09-24T06:49:26.767128Z","shell.execute_reply":"2024-09-24T06:49:26.772751Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/kaggle/working/DINO/models/dino/ops\n","output_type":"stream"}]},{"cell_type":"code","source":"# Build and install the package\n!python setup.py build install","metadata":{"execution":{"iopub.status.busy":"2024-09-24T06:49:35.073060Z","iopub.execute_input":"2024-09-24T06:49:35.073944Z","iopub.status.idle":"2024-09-24T06:50:15.545934Z","shell.execute_reply.started":"2024-09-24T06:49:35.073887Z","shell.execute_reply":"2024-09-24T06:50:15.544803Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:414: UserWarning: The detected CUDA version (12.3) has a minor version mismatch with the version that was used to compile PyTorch (12.4). Most likely this shouldn't be a problem.\n  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:424: UserWarning: There are no g++ version bounds defined for CUDA version 12.3\n  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\nEmitting ninja build file /kaggle/working/DINO/models/dino/ops/build/temp.linux-x86_64-cpython-310/build.ninja...\nCompiling objects...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n[1/3] c++ -MMD -MF /kaggle/working/DINO/models/dino/ops/build/temp.linux-x86_64-cpython-310/kaggle/working/DINO/models/dino/ops/src/cpu/ms_deform_attn_cpu.o.d -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DWITH_CUDA -I/kaggle/working/DINO/models/dino/ops/src -I/opt/conda/lib/python3.10/site-packages/torch/include -I/opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.10 -c -c /kaggle/working/DINO/models/dino/ops/src/cpu/ms_deform_attn_cpu.cpp -o /kaggle/working/DINO/models/dino/ops/build/temp.linux-x86_64-cpython-310/kaggle/working/DINO/models/dino/ops/src/cpu/ms_deform_attn_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n[2/3] c++ -MMD -MF /kaggle/working/DINO/models/dino/ops/build/temp.linux-x86_64-cpython-310/kaggle/working/DINO/models/dino/ops/src/vision.o.d -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DWITH_CUDA -I/kaggle/working/DINO/models/dino/ops/src -I/opt/conda/lib/python3.10/site-packages/torch/include -I/opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.10 -c -c /kaggle/working/DINO/models/dino/ops/src/vision.cpp -o /kaggle/working/DINO/models/dino/ops/build/temp.linux-x86_64-cpython-310/kaggle/working/DINO/models/dino/ops/src/vision.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\nIn file included from /kaggle/working/DINO/models/dino/ops/src/vision.cpp:11:\n/kaggle/working/DINO/models/dino/ops/src/ms_deform_attn.h: In function 'at::Tensor ms_deform_attn_forward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)':\n/kaggle/working/DINO/models/dino/ops/src/ms_deform_attn.h:29:19: warning: 'at::DeprecatedTypeProperties& at::Tensor::type() const' is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n   29 |     if (value.type().is_cuda())\n      |         ~~~~~~~~~~^~\nIn file included from /opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/Tensor.h:3,\n                 from /opt/conda/lib/python3.10/site-packages/torch/include/ATen/Tensor.h:3,\n                 from /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n                 from /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n                 from /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n                 from /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n                 from /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n                 from /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n                 from /opt/conda/lib/python3.10/site-packages/torch/include/torch/extension.h:5,\n                 from /kaggle/working/DINO/models/dino/ops/src/cpu/ms_deform_attn_cpu.h:12,\n                 from /kaggle/working/DINO/models/dino/ops/src/ms_deform_attn.h:13,\n                 from /kaggle/working/DINO/models/dino/ops/src/vision.cpp:11:\n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n  225 |   DeprecatedTypeProperties & type() const {\n      |                              ^~~~\nIn file included from /kaggle/working/DINO/models/dino/ops/src/vision.cpp:11:\n/kaggle/working/DINO/models/dino/ops/src/ms_deform_attn.h: In function 'std::vector<at::Tensor> ms_deform_attn_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)':\n/kaggle/working/DINO/models/dino/ops/src/ms_deform_attn.h:51:19: warning: 'at::DeprecatedTypeProperties& at::Tensor::type() const' is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n   51 |     if (value.type().is_cuda())\n      |         ~~~~~~~~~~^~\nIn file included from /opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/Tensor.h:3,\n                 from /opt/conda/lib/python3.10/site-packages/torch/include/ATen/Tensor.h:3,\n                 from /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n                 from /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n                 from /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n                 from /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n                 from /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n                 from /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n                 from /opt/conda/lib/python3.10/site-packages/torch/include/torch/extension.h:5,\n                 from /kaggle/working/DINO/models/dino/ops/src/cpu/ms_deform_attn_cpu.h:12,\n                 from /kaggle/working/DINO/models/dino/ops/src/ms_deform_attn.h:13,\n                 from /kaggle/working/DINO/models/dino/ops/src/vision.cpp:11:\n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n  225 |   DeprecatedTypeProperties & type() const {\n      |                              ^~~~\n[3/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /kaggle/working/DINO/models/dino/ops/build/temp.linux-x86_64-cpython-310/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.o.d -DWITH_CUDA -I/kaggle/working/DINO/models/dino/ops/src -I/opt/conda/lib/python3.10/site-packages/torch/include -I/opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.10/site-packages/torch/include/TH -I/opt/conda/lib/python3.10/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.10 -c -c /kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu -o /kaggle/working/DINO/models/dino/ops/build/temp.linux-x86_64-cpython-310/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++17\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_im2col_cuda.cuh(261): warning #177-D: variable \"q_col\" was declared but never referenced\n      const int q_col = _temp % num_query;\n                ^\n          detected during instantiation of \"void ms_deformable_im2col_cuda(cudaStream_t, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *) [with scalar_t=double]\" at line 64 of /kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu\n\nRemark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_im2col_cuda.cuh(762): warning #177-D: variable \"q_col\" was declared but never referenced\n      const int q_col = _temp % num_query;\n                ^\n          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" at line 134 of /kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu\n\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_im2col_cuda.cuh(872): warning #177-D: variable \"q_col\" was declared but never referenced\n      const int q_col = _temp % num_query;\n                ^\n          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" at line 134 of /kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu\n\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_im2col_cuda.cuh(331): warning #177-D: variable \"q_col\" was declared but never referenced\n      const int q_col = _temp % num_query;\n                ^\n          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" at line 134 of /kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu\n\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_im2col_cuda.cuh(436): warning #177-D: variable \"q_col\" was declared but never referenced\n      const int q_col = _temp % num_query;\n                ^\n          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" at line 134 of /kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu\n\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_im2col_cuda.cuh(544): warning #177-D: variable \"q_col\" was declared but never referenced\n      const int q_col = _temp % num_query;\n                ^\n          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" at line 134 of /kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu\n\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_im2col_cuda.cuh(649): warning #177-D: variable \"q_col\" was declared but never referenced\n      const int q_col = _temp % num_query;\n                ^\n          detected during instantiation of \"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\" at line 134 of /kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu\n\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu: In function 'at::Tensor ms_deform_attn_cuda_forward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)':\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:34:61: warning: 'at::DeprecatedTypeProperties& at::Tensor::type() const' is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n   34 |     AT_ASSERTM(value.type().is_cuda(), \"value must be a CUDA tensor\");\n      |                                                   ~~~~~~~~~~^~\n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here\n  225 |   DeprecatedTypeProperties & type() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:35:70: warning: 'at::DeprecatedTypeProperties& at::Tensor::type() const' is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n   35 |     AT_ASSERTM(spatial_shapes.type().is_cuda(), \"spatial_shapes must be a CUDA tensor\");\n      |                                                   ~~~~~~~~~~~~~~~~~~~^~\n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here\n  225 |   DeprecatedTypeProperties & type() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:36:73: warning: 'at::DeprecatedTypeProperties& at::Tensor::type() const' is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n   36 |     AT_ASSERTM(level_start_index.type().is_cuda(), \"level_start_index must be a CUDA tensor\");\n      |                                                   ~~~~~~~~~~~~~~~~~~~~~~^~\n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here\n  225 |   DeprecatedTypeProperties & type() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:37:68: warning: 'at::DeprecatedTypeProperties& at::Tensor::type() const' is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n   37 |     AT_ASSERTM(sampling_loc.type().is_cuda(), \"sampling_loc must be a CUDA tensor\");\n      |                                                   ~~~~~~~~~~~~~~~~~^~\n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here\n  225 |   DeprecatedTypeProperties & type() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:38:67: warning: 'at::DeprecatedTypeProperties& at::Tensor::type() const' is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n   38 |     AT_ASSERTM(attn_weight.type().is_cuda(), \"attn_weight must be a CUDA tensor\");\n      |                                                   ~~~~~~~~~~~~~~~~^~\n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here\n  225 |   DeprecatedTypeProperties & type() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu: In lambda function:\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:42: warning: 'at::DeprecatedTypeProperties& at::Tensor::type() const' is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n      |                              ~~~~~~~~~~~~^~\n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here\n  225 |   DeprecatedTypeProperties & type() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:163: warning: 'c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)' is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n      |                                                                                                                                                                   ^         \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/Dispatch.h:109:1: note: declared here\n  109 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n      | ^~~~~~~~~~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu: In lambda function:\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:1047: warning: 'T* at::Tensor::data() const [with T = double]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:1133: warning: 'T* at::Tensor::data() const [with T = long int]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:1176: warning: 'T* at::Tensor::data() const [with T = long int]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:1209: warning: 'T* at::Tensor::data() const [with T = double]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:1292: warning: 'T* at::Tensor::data() const [with T = double]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:1450: warning: 'T* at::Tensor::data() const [with T = double]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu: In lambda function:\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:2314: warning: 'T* at::Tensor::data() const [with T = float]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:2400: warning: 'T* at::Tensor::data() const [with T = long int]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:2443: warning: 'T* at::Tensor::data() const [with T = long int]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:2475: warning: 'T* at::Tensor::data() const [with T = float]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:2557: warning: 'T* at::Tensor::data() const [with T = float]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:64:2714: warning: 'T* at::Tensor::data() const [with T = float]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu: In function 'std::vector<at::Tensor> ms_deform_attn_cuda_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)':\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:100:61: warning: 'at::DeprecatedTypeProperties& at::Tensor::type() const' is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n  100 |     AT_ASSERTM(value.type().is_cuda(), \"value must be a CUDA tensor\");\n      |                                                   ~~~~~~~~~~^~\n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here\n  225 |   DeprecatedTypeProperties & type() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:101:70: warning: 'at::DeprecatedTypeProperties& at::Tensor::type() const' is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n  101 |     AT_ASSERTM(spatial_shapes.type().is_cuda(), \"spatial_shapes must be a CUDA tensor\");\n      |                                                   ~~~~~~~~~~~~~~~~~~~^~\n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here\n  225 |   DeprecatedTypeProperties & type() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:102:73: warning: 'at::DeprecatedTypeProperties& at::Tensor::type() const' is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n  102 |     AT_ASSERTM(level_start_index.type().is_cuda(), \"level_start_index must be a CUDA tensor\");\n      |                                                   ~~~~~~~~~~~~~~~~~~~~~~^~\n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here\n  225 |   DeprecatedTypeProperties & type() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:103:68: warning: 'at::DeprecatedTypeProperties& at::Tensor::type() const' is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n  103 |     AT_ASSERTM(sampling_loc.type().is_cuda(), \"sampling_loc must be a CUDA tensor\");\n      |                                                   ~~~~~~~~~~~~~~~~~^~\n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here\n  225 |   DeprecatedTypeProperties & type() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:104:67: warning: 'at::DeprecatedTypeProperties& at::Tensor::type() const' is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n  104 |     AT_ASSERTM(attn_weight.type().is_cuda(), \"attn_weight must be a CUDA tensor\");\n      |                                                   ~~~~~~~~~~~~~~~~^~\n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here\n  225 |   DeprecatedTypeProperties & type() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:105:67: warning: 'at::DeprecatedTypeProperties& at::Tensor::type() const' is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n  105 |     AT_ASSERTM(grad_output.type().is_cuda(), \"grad_output must be a CUDA tensor\");\n      |                                                   ~~~~~~~~~~~~~~~~^~\n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here\n  225 |   DeprecatedTypeProperties & type() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu: In lambda function:\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:42: warning: 'at::DeprecatedTypeProperties& at::Tensor::type() const' is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                              ~~~~~~~~~~~~^~\n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here\n  225 |   DeprecatedTypeProperties & type() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:164: warning: 'c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)' is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                    ^         \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/Dispatch.h:109:1: note: declared here\n  109 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n      | ^~~~~~~~~~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu: In lambda function:\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:1057: warning: 'T* at::Tensor::data() const [with T = double]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:1083: warning: 'T* at::Tensor::data() const [with T = double]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:1169: warning: 'T* at::Tensor::data() const [with T = long int]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:1212: warning: 'T* at::Tensor::data() const [with T = long int]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:1245: warning: 'T* at::Tensor::data() const [with T = double]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:1328: warning: 'T* at::Tensor::data() const [with T = double]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:1489: warning: 'T* at::Tensor::data() const [with T = double]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:1573: warning: 'T* at::Tensor::data() const [with T = double]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:1661: warning: 'T* at::Tensor::data() const [with T = double]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu: In lambda function:\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:2586: warning: 'T* at::Tensor::data() const [with T = float]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:2611: warning: 'T* at::Tensor::data() const [with T = float]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:2697: warning: 'T* at::Tensor::data() const [with T = long int]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:2740: warning: 'T* at::Tensor::data() const [with T = long int]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:2772: warning: 'T* at::Tensor::data() const [with T = float]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:2854: warning: 'T* at::Tensor::data() const [with T = float]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:3014: warning: 'T* at::Tensor::data() const [with T = float]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:3097: warning: 'T* at::Tensor::data() const [with T = float]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/kaggle/working/DINO/models/dino/ops/src/cuda/ms_deform_attn_cuda.cu:134:3184: warning: 'T* at::Tensor::data() const [with T = float]' is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ^ \n/opt/conda/lib/python3.10/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here\n  247 |   T * data() const {\n      | ^ ~~\n/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n!!\n\n        ********************************************************************************\n        Please avoid running ``setup.py`` directly.\n        Instead, use pypa/build, pypa/installer or other\n        standards-based tools.\n\n        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n        ********************************************************************************\n\n!!\n  self.initialize_options()\n/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n!!\n\n        ********************************************************************************\n        Please avoid running ``setup.py`` and ``easy_install``.\n        Instead, use pypa/build, pypa/installer or other\n        standards-based tools.\n\n        See https://github.com/pypa/setuptools/issues/917 for details.\n        ********************************************************************************\n\n!!\n  self.initialize_options()\n","output_type":"stream"}]},{"cell_type":"code","source":"# Run the unit tests\n!python test.py","metadata":{"execution":{"iopub.status.busy":"2024-09-24T06:51:32.699100Z","iopub.execute_input":"2024-09-24T06:51:32.699536Z","iopub.status.idle":"2024-09-24T06:53:02.607232Z","shell.execute_reply.started":"2024-09-24T06:51:32.699497Z","shell.execute_reply":"2024-09-24T06:53:02.606080Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"* True check_forward_equal_with_pytorch_double: max_abs_err 8.67e-19 max_rel_err 2.35e-16\n* True check_forward_equal_with_pytorch_float: max_abs_err 4.66e-10 max_rel_err 1.13e-07\n* True check_gradient_numerical(D=30)\n* True check_gradient_numerical(D=32)\n* True check_gradient_numerical(D=64)\n* True check_gradient_numerical(D=71)\n* True check_gradient_numerical(D=1025)\nTraceback (most recent call last):\n  File \"/kaggle/working/DINO/models/dino/ops/test.py\", line 86, in <module>\n    check_gradient_numerical(channels, True, True, True)\n  File \"/kaggle/working/DINO/models/dino/ops/test.py\", line 76, in check_gradient_numerical\n    gradok = gradcheck(func, (value.double(), shapes, level_start_index, sampling_locations.double(), attention_weights.double(), im2col_step))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/gradcheck.py\", line 2053, in gradcheck\n    return _gradcheck_helper(**args)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/gradcheck.py\", line 2082, in _gradcheck_helper\n    _gradcheck_real_imag(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/gradcheck.py\", line 1492, in _gradcheck_real_imag\n    gradcheck_fn(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/gradcheck.py\", line 1627, in _slow_gradcheck\n    analytical = _check_analytical_jacobian_attributes(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/gradcheck.py\", line 777, in _check_analytical_jacobian_attributes\n    vjps2 = _compute_analytical_jacobian_rows(vjp_fn, output.clone())\n  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/gradcheck.py\", line 894, in _compute_analytical_jacobian_rows\n    grad_inputs = vjp_fn(grad_out_base)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/gradcheck.py\", line 767, in vjp_fn\n    return torch.autograd.grad(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 436, in grad\n    result = _engine_run_backward(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py\", line 306, in apply\n    return user_fn(self, *args)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py\", line 599, in wrapper\n    outputs = fn(ctx, *args)\n  File \"/kaggle/working/DINO/models/dino/ops/functions/ms_deform_attn_func.py\", line 35, in backward\n    MSDA.ms_deform_attn_backward(\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 21.12 MiB is free. Process 19868 has 15.87 GiB memory in use. Of the allocated memory 15.07 GiB is allocated by PyTorch, and 527.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Change back to the original directory\n%cd ../../..","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:07:39.269686Z","iopub.execute_input":"2024-09-24T11:07:39.270583Z","iopub.status.idle":"2024-09-24T11:07:39.276295Z","shell.execute_reply.started":"2024-09-24T11:07:39.270542Z","shell.execute_reply":"2024-09-24T11:07:39.275300Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"/\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install yapf==0.32.0","metadata":{"execution":{"iopub.status.busy":"2024-09-24T06:53:36.028340Z","iopub.execute_input":"2024-09-24T06:53:36.029275Z","iopub.status.idle":"2024-09-24T06:53:49.577427Z","shell.execute_reply.started":"2024-09-24T06:53:36.029231Z","shell.execute_reply":"2024-09-24T06:53:49.576205Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Collecting yapf==0.32.0\n  Downloading yapf-0.32.0-py2.py3-none-any.whl.metadata (34 kB)\nDownloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m190.2/190.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: yapf\n  Attempting uninstall: yapf\n    Found existing installation: yapf 0.40.2\n    Uninstalling yapf-0.40.2:\n      Successfully uninstalled yapf-0.40.2\nSuccessfully installed yapf-0.32.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Handle NumPy attribute error","metadata":{}},{"cell_type":"code","source":"# Define the path to the file\nfile_path = '/opt/conda/lib/python3.10/site-packages/pycocotools/cocoeval.py'\n\n# Read the file, replace np.float with float, and write it back\nwith open(file_path, 'r') as file:\n    file_contents = file.read()\n\n\n# Replace np.float with float\nupdated_contents = file_contents.replace('np.float', 'float')\n\n# Write the updated contents back to the file\nwith open(file_path, 'w') as file:\n    file.write(updated_contents)\n\nprint(\"File updated successfully.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-24T09:28:10.417536Z","iopub.execute_input":"2024-09-24T09:28:10.418452Z","iopub.status.idle":"2024-09-24T09:28:10.425263Z","shell.execute_reply.started":"2024-09-24T09:28:10.418408Z","shell.execute_reply":"2024-09-24T09:28:10.424256Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"File updated successfully.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Performing evaluations on validation set","metadata":{}},{"cell_type":"code","source":"!bash scripts/DINO_eval.sh /kaggle/input/pedestrian-dataset/coco2017 /kaggle/input/dino_4scale/other/default/1/checkpoint0011_4scale.pth","metadata":{"execution":{"iopub.status.busy":"2024-09-24T09:30:12.061300Z","iopub.execute_input":"2024-09-24T09:30:12.062211Z","iopub.status.idle":"2024-09-24T09:30:29.359045Z","shell.execute_reply.started":"2024-09-24T09:30:12.062173Z","shell.execute_reply":"2024-09-24T09:30:29.357846Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Not using distributed mode\nLoading config file from config/DINO/DINO_4scale.py\n[09/24 09:30:16.685]: git:\n  sha: d84a491d41898b3befd8294d1cf2614661fc0953, status: clean, branch: main\n\n[09/24 09:30:16.685]: Command: main.py --output_dir logs/DINO/R50-MS4-%j -c config/DINO/DINO_4scale.py --coco_path /kaggle/input/pedestrian-dataset/coco2017 --eval --resume /kaggle/input/dino_4scale/other/default/1/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0\n[09/24 09:30:16.686]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json\n[09/24 09:30:16.686]: world size: 1\n[09/24 09:30:16.687]: rank: 0\n[09/24 09:30:16.687]: local_rank: 0\n[09/24 09:30:16.687]: args: Namespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/kaggle/input/pedestrian-dataset/coco2017', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='/kaggle/input/dino_4scale/other/default/1/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)\n\nNamespace(config_file='config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='/kaggle/input/pedestrian-dataset/coco2017', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='/kaggle/input/dino_4scale/other/default/1/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=10, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n[09/24 09:30:18.773]: number of params:46670782\n[09/24 09:30:18.776]: params:\n{\n  \"transformer.level_embed\": 1024,\n  \"transformer.encoder.layers.0.self_attn.sampling_offsets.weight\": 65536,\n  \"transformer.encoder.layers.0.self_attn.sampling_offsets.bias\": 256,\n  \"transformer.encoder.layers.0.self_attn.attention_weights.weight\": 32768,\n  \"transformer.encoder.layers.0.self_attn.attention_weights.bias\": 128,\n  \"transformer.encoder.layers.0.self_attn.value_proj.weight\": 65536,\n  \"transformer.encoder.layers.0.self_attn.value_proj.bias\": 256,\n  \"transformer.encoder.layers.0.self_attn.output_proj.weight\": 65536,\n  \"transformer.encoder.layers.0.self_attn.output_proj.bias\": 256,\n  \"transformer.encoder.layers.0.norm1.weight\": 256,\n  \"transformer.encoder.layers.0.norm1.bias\": 256,\n  \"transformer.encoder.layers.0.linear1.weight\": 524288,\n  \"transformer.encoder.layers.0.linear1.bias\": 2048,\n  \"transformer.encoder.layers.0.linear2.weight\": 524288,\n  \"transformer.encoder.layers.0.linear2.bias\": 256,\n  \"transformer.encoder.layers.0.norm2.weight\": 256,\n  \"transformer.encoder.layers.0.norm2.bias\": 256,\n  \"transformer.encoder.layers.1.self_attn.sampling_offsets.weight\": 65536,\n  \"transformer.encoder.layers.1.self_attn.sampling_offsets.bias\": 256,\n  \"transformer.encoder.layers.1.self_attn.attention_weights.weight\": 32768,\n  \"transformer.encoder.layers.1.self_attn.attention_weights.bias\": 128,\n  \"transformer.encoder.layers.1.self_attn.value_proj.weight\": 65536,\n  \"transformer.encoder.layers.1.self_attn.value_proj.bias\": 256,\n  \"transformer.encoder.layers.1.self_attn.output_proj.weight\": 65536,\n  \"transformer.encoder.layers.1.self_attn.output_proj.bias\": 256,\n  \"transformer.encoder.layers.1.norm1.weight\": 256,\n  \"transformer.encoder.layers.1.norm1.bias\": 256,\n  \"transformer.encoder.layers.1.linear1.weight\": 524288,\n  \"transformer.encoder.layers.1.linear1.bias\": 2048,\n  \"transformer.encoder.layers.1.linear2.weight\": 524288,\n  \"transformer.encoder.layers.1.linear2.bias\": 256,\n  \"transformer.encoder.layers.1.norm2.weight\": 256,\n  \"transformer.encoder.layers.1.norm2.bias\": 256,\n  \"transformer.encoder.layers.2.self_attn.sampling_offsets.weight\": 65536,\n  \"transformer.encoder.layers.2.self_attn.sampling_offsets.bias\": 256,\n  \"transformer.encoder.layers.2.self_attn.attention_weights.weight\": 32768,\n  \"transformer.encoder.layers.2.self_attn.attention_weights.bias\": 128,\n  \"transformer.encoder.layers.2.self_attn.value_proj.weight\": 65536,\n  \"transformer.encoder.layers.2.self_attn.value_proj.bias\": 256,\n  \"transformer.encoder.layers.2.self_attn.output_proj.weight\": 65536,\n  \"transformer.encoder.layers.2.self_attn.output_proj.bias\": 256,\n  \"transformer.encoder.layers.2.norm1.weight\": 256,\n  \"transformer.encoder.layers.2.norm1.bias\": 256,\n  \"transformer.encoder.layers.2.linear1.weight\": 524288,\n  \"transformer.encoder.layers.2.linear1.bias\": 2048,\n  \"transformer.encoder.layers.2.linear2.weight\": 524288,\n  \"transformer.encoder.layers.2.linear2.bias\": 256,\n  \"transformer.encoder.layers.2.norm2.weight\": 256,\n  \"transformer.encoder.layers.2.norm2.bias\": 256,\n  \"transformer.encoder.layers.3.self_attn.sampling_offsets.weight\": 65536,\n  \"transformer.encoder.layers.3.self_attn.sampling_offsets.bias\": 256,\n  \"transformer.encoder.layers.3.self_attn.attention_weights.weight\": 32768,\n  \"transformer.encoder.layers.3.self_attn.attention_weights.bias\": 128,\n  \"transformer.encoder.layers.3.self_attn.value_proj.weight\": 65536,\n  \"transformer.encoder.layers.3.self_attn.value_proj.bias\": 256,\n  \"transformer.encoder.layers.3.self_attn.output_proj.weight\": 65536,\n  \"transformer.encoder.layers.3.self_attn.output_proj.bias\": 256,\n  \"transformer.encoder.layers.3.norm1.weight\": 256,\n  \"transformer.encoder.layers.3.norm1.bias\": 256,\n  \"transformer.encoder.layers.3.linear1.weight\": 524288,\n  \"transformer.encoder.layers.3.linear1.bias\": 2048,\n  \"transformer.encoder.layers.3.linear2.weight\": 524288,\n  \"transformer.encoder.layers.3.linear2.bias\": 256,\n  \"transformer.encoder.layers.3.norm2.weight\": 256,\n  \"transformer.encoder.layers.3.norm2.bias\": 256,\n  \"transformer.encoder.layers.4.self_attn.sampling_offsets.weight\": 65536,\n  \"transformer.encoder.layers.4.self_attn.sampling_offsets.bias\": 256,\n  \"transformer.encoder.layers.4.self_attn.attention_weights.weight\": 32768,\n  \"transformer.encoder.layers.4.self_attn.attention_weights.bias\": 128,\n  \"transformer.encoder.layers.4.self_attn.value_proj.weight\": 65536,\n  \"transformer.encoder.layers.4.self_attn.value_proj.bias\": 256,\n  \"transformer.encoder.layers.4.self_attn.output_proj.weight\": 65536,\n  \"transformer.encoder.layers.4.self_attn.output_proj.bias\": 256,\n  \"transformer.encoder.layers.4.norm1.weight\": 256,\n  \"transformer.encoder.layers.4.norm1.bias\": 256,\n  \"transformer.encoder.layers.4.linear1.weight\": 524288,\n  \"transformer.encoder.layers.4.linear1.bias\": 2048,\n  \"transformer.encoder.layers.4.linear2.weight\": 524288,\n  \"transformer.encoder.layers.4.linear2.bias\": 256,\n  \"transformer.encoder.layers.4.norm2.weight\": 256,\n  \"transformer.encoder.layers.4.norm2.bias\": 256,\n  \"transformer.encoder.layers.5.self_attn.sampling_offsets.weight\": 65536,\n  \"transformer.encoder.layers.5.self_attn.sampling_offsets.bias\": 256,\n  \"transformer.encoder.layers.5.self_attn.attention_weights.weight\": 32768,\n  \"transformer.encoder.layers.5.self_attn.attention_weights.bias\": 128,\n  \"transformer.encoder.layers.5.self_attn.value_proj.weight\": 65536,\n  \"transformer.encoder.layers.5.self_attn.value_proj.bias\": 256,\n  \"transformer.encoder.layers.5.self_attn.output_proj.weight\": 65536,\n  \"transformer.encoder.layers.5.self_attn.output_proj.bias\": 256,\n  \"transformer.encoder.layers.5.norm1.weight\": 256,\n  \"transformer.encoder.layers.5.norm1.bias\": 256,\n  \"transformer.encoder.layers.5.linear1.weight\": 524288,\n  \"transformer.encoder.layers.5.linear1.bias\": 2048,\n  \"transformer.encoder.layers.5.linear2.weight\": 524288,\n  \"transformer.encoder.layers.5.linear2.bias\": 256,\n  \"transformer.encoder.layers.5.norm2.weight\": 256,\n  \"transformer.encoder.layers.5.norm2.bias\": 256,\n  \"transformer.decoder.layers.0.cross_attn.sampling_offsets.weight\": 65536,\n  \"transformer.decoder.layers.0.cross_attn.sampling_offsets.bias\": 256,\n  \"transformer.decoder.layers.0.cross_attn.attention_weights.weight\": 32768,\n  \"transformer.decoder.layers.0.cross_attn.attention_weights.bias\": 128,\n  \"transformer.decoder.layers.0.cross_attn.value_proj.weight\": 65536,\n  \"transformer.decoder.layers.0.cross_attn.value_proj.bias\": 256,\n  \"transformer.decoder.layers.0.cross_attn.output_proj.weight\": 65536,\n  \"transformer.decoder.layers.0.cross_attn.output_proj.bias\": 256,\n  \"transformer.decoder.layers.0.norm1.weight\": 256,\n  \"transformer.decoder.layers.0.norm1.bias\": 256,\n  \"transformer.decoder.layers.0.self_attn.in_proj_weight\": 196608,\n  \"transformer.decoder.layers.0.self_attn.in_proj_bias\": 768,\n  \"transformer.decoder.layers.0.self_attn.out_proj.weight\": 65536,\n  \"transformer.decoder.layers.0.self_attn.out_proj.bias\": 256,\n  \"transformer.decoder.layers.0.norm2.weight\": 256,\n  \"transformer.decoder.layers.0.norm2.bias\": 256,\n  \"transformer.decoder.layers.0.linear1.weight\": 524288,\n  \"transformer.decoder.layers.0.linear1.bias\": 2048,\n  \"transformer.decoder.layers.0.linear2.weight\": 524288,\n  \"transformer.decoder.layers.0.linear2.bias\": 256,\n  \"transformer.decoder.layers.0.norm3.weight\": 256,\n  \"transformer.decoder.layers.0.norm3.bias\": 256,\n  \"transformer.decoder.layers.1.cross_attn.sampling_offsets.weight\": 65536,\n  \"transformer.decoder.layers.1.cross_attn.sampling_offsets.bias\": 256,\n  \"transformer.decoder.layers.1.cross_attn.attention_weights.weight\": 32768,\n  \"transformer.decoder.layers.1.cross_attn.attention_weights.bias\": 128,\n  \"transformer.decoder.layers.1.cross_attn.value_proj.weight\": 65536,\n  \"transformer.decoder.layers.1.cross_attn.value_proj.bias\": 256,\n  \"transformer.decoder.layers.1.cross_attn.output_proj.weight\": 65536,\n  \"transformer.decoder.layers.1.cross_attn.output_proj.bias\": 256,\n  \"transformer.decoder.layers.1.norm1.weight\": 256,\n  \"transformer.decoder.layers.1.norm1.bias\": 256,\n  \"transformer.decoder.layers.1.self_attn.in_proj_weight\": 196608,\n  \"transformer.decoder.layers.1.self_attn.in_proj_bias\": 768,\n  \"transformer.decoder.layers.1.self_attn.out_proj.weight\": 65536,\n  \"transformer.decoder.layers.1.self_attn.out_proj.bias\": 256,\n  \"transformer.decoder.layers.1.norm2.weight\": 256,\n  \"transformer.decoder.layers.1.norm2.bias\": 256,\n  \"transformer.decoder.layers.1.linear1.weight\": 524288,\n  \"transformer.decoder.layers.1.linear1.bias\": 2048,\n  \"transformer.decoder.layers.1.linear2.weight\": 524288,\n  \"transformer.decoder.layers.1.linear2.bias\": 256,\n  \"transformer.decoder.layers.1.norm3.weight\": 256,\n  \"transformer.decoder.layers.1.norm3.bias\": 256,\n  \"transformer.decoder.layers.2.cross_attn.sampling_offsets.weight\": 65536,\n  \"transformer.decoder.layers.2.cross_attn.sampling_offsets.bias\": 256,\n  \"transformer.decoder.layers.2.cross_attn.attention_weights.weight\": 32768,\n  \"transformer.decoder.layers.2.cross_attn.attention_weights.bias\": 128,\n  \"transformer.decoder.layers.2.cross_attn.value_proj.weight\": 65536,\n  \"transformer.decoder.layers.2.cross_attn.value_proj.bias\": 256,\n  \"transformer.decoder.layers.2.cross_attn.output_proj.weight\": 65536,\n  \"transformer.decoder.layers.2.cross_attn.output_proj.bias\": 256,\n  \"transformer.decoder.layers.2.norm1.weight\": 256,\n  \"transformer.decoder.layers.2.norm1.bias\": 256,\n  \"transformer.decoder.layers.2.self_attn.in_proj_weight\": 196608,\n  \"transformer.decoder.layers.2.self_attn.in_proj_bias\": 768,\n  \"transformer.decoder.layers.2.self_attn.out_proj.weight\": 65536,\n  \"transformer.decoder.layers.2.self_attn.out_proj.bias\": 256,\n  \"transformer.decoder.layers.2.norm2.weight\": 256,\n  \"transformer.decoder.layers.2.norm2.bias\": 256,\n  \"transformer.decoder.layers.2.linear1.weight\": 524288,\n  \"transformer.decoder.layers.2.linear1.bias\": 2048,\n  \"transformer.decoder.layers.2.linear2.weight\": 524288,\n  \"transformer.decoder.layers.2.linear2.bias\": 256,\n  \"transformer.decoder.layers.2.norm3.weight\": 256,\n  \"transformer.decoder.layers.2.norm3.bias\": 256,\n  \"transformer.decoder.layers.3.cross_attn.sampling_offsets.weight\": 65536,\n  \"transformer.decoder.layers.3.cross_attn.sampling_offsets.bias\": 256,\n  \"transformer.decoder.layers.3.cross_attn.attention_weights.weight\": 32768,\n  \"transformer.decoder.layers.3.cross_attn.attention_weights.bias\": 128,\n  \"transformer.decoder.layers.3.cross_attn.value_proj.weight\": 65536,\n  \"transformer.decoder.layers.3.cross_attn.value_proj.bias\": 256,\n  \"transformer.decoder.layers.3.cross_attn.output_proj.weight\": 65536,\n  \"transformer.decoder.layers.3.cross_attn.output_proj.bias\": 256,\n  \"transformer.decoder.layers.3.norm1.weight\": 256,\n  \"transformer.decoder.layers.3.norm1.bias\": 256,\n  \"transformer.decoder.layers.3.self_attn.in_proj_weight\": 196608,\n  \"transformer.decoder.layers.3.self_attn.in_proj_bias\": 768,\n  \"transformer.decoder.layers.3.self_attn.out_proj.weight\": 65536,\n  \"transformer.decoder.layers.3.self_attn.out_proj.bias\": 256,\n  \"transformer.decoder.layers.3.norm2.weight\": 256,\n  \"transformer.decoder.layers.3.norm2.bias\": 256,\n  \"transformer.decoder.layers.3.linear1.weight\": 524288,\n  \"transformer.decoder.layers.3.linear1.bias\": 2048,\n  \"transformer.decoder.layers.3.linear2.weight\": 524288,\n  \"transformer.decoder.layers.3.linear2.bias\": 256,\n  \"transformer.decoder.layers.3.norm3.weight\": 256,\n  \"transformer.decoder.layers.3.norm3.bias\": 256,\n  \"transformer.decoder.layers.4.cross_attn.sampling_offsets.weight\": 65536,\n  \"transformer.decoder.layers.4.cross_attn.sampling_offsets.bias\": 256,\n  \"transformer.decoder.layers.4.cross_attn.attention_weights.weight\": 32768,\n  \"transformer.decoder.layers.4.cross_attn.attention_weights.bias\": 128,\n  \"transformer.decoder.layers.4.cross_attn.value_proj.weight\": 65536,\n  \"transformer.decoder.layers.4.cross_attn.value_proj.bias\": 256,\n  \"transformer.decoder.layers.4.cross_attn.output_proj.weight\": 65536,\n  \"transformer.decoder.layers.4.cross_attn.output_proj.bias\": 256,\n  \"transformer.decoder.layers.4.norm1.weight\": 256,\n  \"transformer.decoder.layers.4.norm1.bias\": 256,\n  \"transformer.decoder.layers.4.self_attn.in_proj_weight\": 196608,\n  \"transformer.decoder.layers.4.self_attn.in_proj_bias\": 768,\n  \"transformer.decoder.layers.4.self_attn.out_proj.weight\": 65536,\n  \"transformer.decoder.layers.4.self_attn.out_proj.bias\": 256,\n  \"transformer.decoder.layers.4.norm2.weight\": 256,\n  \"transformer.decoder.layers.4.norm2.bias\": 256,\n  \"transformer.decoder.layers.4.linear1.weight\": 524288,\n  \"transformer.decoder.layers.4.linear1.bias\": 2048,\n  \"transformer.decoder.layers.4.linear2.weight\": 524288,\n  \"transformer.decoder.layers.4.linear2.bias\": 256,\n  \"transformer.decoder.layers.4.norm3.weight\": 256,\n  \"transformer.decoder.layers.4.norm3.bias\": 256,\n  \"transformer.decoder.layers.5.cross_attn.sampling_offsets.weight\": 65536,\n  \"transformer.decoder.layers.5.cross_attn.sampling_offsets.bias\": 256,\n  \"transformer.decoder.layers.5.cross_attn.attention_weights.weight\": 32768,\n  \"transformer.decoder.layers.5.cross_attn.attention_weights.bias\": 128,\n  \"transformer.decoder.layers.5.cross_attn.value_proj.weight\": 65536,\n  \"transformer.decoder.layers.5.cross_attn.value_proj.bias\": 256,\n  \"transformer.decoder.layers.5.cross_attn.output_proj.weight\": 65536,\n  \"transformer.decoder.layers.5.cross_attn.output_proj.bias\": 256,\n  \"transformer.decoder.layers.5.norm1.weight\": 256,\n  \"transformer.decoder.layers.5.norm1.bias\": 256,\n  \"transformer.decoder.layers.5.self_attn.in_proj_weight\": 196608,\n  \"transformer.decoder.layers.5.self_attn.in_proj_bias\": 768,\n  \"transformer.decoder.layers.5.self_attn.out_proj.weight\": 65536,\n  \"transformer.decoder.layers.5.self_attn.out_proj.bias\": 256,\n  \"transformer.decoder.layers.5.norm2.weight\": 256,\n  \"transformer.decoder.layers.5.norm2.bias\": 256,\n  \"transformer.decoder.layers.5.linear1.weight\": 524288,\n  \"transformer.decoder.layers.5.linear1.bias\": 2048,\n  \"transformer.decoder.layers.5.linear2.weight\": 524288,\n  \"transformer.decoder.layers.5.linear2.bias\": 256,\n  \"transformer.decoder.layers.5.norm3.weight\": 256,\n  \"transformer.decoder.layers.5.norm3.bias\": 256,\n  \"transformer.decoder.norm.weight\": 256,\n  \"transformer.decoder.norm.bias\": 256,\n  \"transformer.decoder.ref_point_head.layers.0.weight\": 131072,\n  \"transformer.decoder.ref_point_head.layers.0.bias\": 256,\n  \"transformer.decoder.ref_point_head.layers.1.weight\": 65536,\n  \"transformer.decoder.ref_point_head.layers.1.bias\": 256,\n  \"transformer.decoder.bbox_embed.0.layers.0.weight\": 65536,\n  \"transformer.decoder.bbox_embed.0.layers.0.bias\": 256,\n  \"transformer.decoder.bbox_embed.0.layers.1.weight\": 65536,\n  \"transformer.decoder.bbox_embed.0.layers.1.bias\": 256,\n  \"transformer.decoder.bbox_embed.0.layers.2.weight\": 1024,\n  \"transformer.decoder.bbox_embed.0.layers.2.bias\": 4,\n  \"transformer.decoder.class_embed.0.weight\": 23296,\n  \"transformer.decoder.class_embed.0.bias\": 91,\n  \"transformer.tgt_embed.weight\": 230400,\n  \"transformer.enc_output.weight\": 65536,\n  \"transformer.enc_output.bias\": 256,\n  \"transformer.enc_output_norm.weight\": 256,\n  \"transformer.enc_output_norm.bias\": 256,\n  \"transformer.enc_out_bbox_embed.layers.0.weight\": 65536,\n  \"transformer.enc_out_bbox_embed.layers.0.bias\": 256,\n  \"transformer.enc_out_bbox_embed.layers.1.weight\": 65536,\n  \"transformer.enc_out_bbox_embed.layers.1.bias\": 256,\n  \"transformer.enc_out_bbox_embed.layers.2.weight\": 1024,\n  \"transformer.enc_out_bbox_embed.layers.2.bias\": 4,\n  \"transformer.enc_out_class_embed.weight\": 23296,\n  \"transformer.enc_out_class_embed.bias\": 91,\n  \"label_enc.weight\": 23552,\n  \"input_proj.0.0.weight\": 131072,\n  \"input_proj.0.0.bias\": 256,\n  \"input_proj.0.1.weight\": 256,\n  \"input_proj.0.1.bias\": 256,\n  \"input_proj.1.0.weight\": 262144,\n  \"input_proj.1.0.bias\": 256,\n  \"input_proj.1.1.weight\": 256,\n  \"input_proj.1.1.bias\": 256,\n  \"input_proj.2.0.weight\": 524288,\n  \"input_proj.2.0.bias\": 256,\n  \"input_proj.2.1.weight\": 256,\n  \"input_proj.2.1.bias\": 256,\n  \"input_proj.3.0.weight\": 4718592,\n  \"input_proj.3.0.bias\": 256,\n  \"input_proj.3.1.weight\": 256,\n  \"input_proj.3.1.bias\": 256,\n  \"backbone.0.body.layer2.0.conv1.weight\": 32768,\n  \"backbone.0.body.layer2.0.conv2.weight\": 147456,\n  \"backbone.0.body.layer2.0.conv3.weight\": 65536,\n  \"backbone.0.body.layer2.0.downsample.0.weight\": 131072,\n  \"backbone.0.body.layer2.1.conv1.weight\": 65536,\n  \"backbone.0.body.layer2.1.conv2.weight\": 147456,\n  \"backbone.0.body.layer2.1.conv3.weight\": 65536,\n  \"backbone.0.body.layer2.2.conv1.weight\": 65536,\n  \"backbone.0.body.layer2.2.conv2.weight\": 147456,\n  \"backbone.0.body.layer2.2.conv3.weight\": 65536,\n  \"backbone.0.body.layer2.3.conv1.weight\": 65536,\n  \"backbone.0.body.layer2.3.conv2.weight\": 147456,\n  \"backbone.0.body.layer2.3.conv3.weight\": 65536,\n  \"backbone.0.body.layer3.0.conv1.weight\": 131072,\n  \"backbone.0.body.layer3.0.conv2.weight\": 589824,\n  \"backbone.0.body.layer3.0.conv3.weight\": 262144,\n  \"backbone.0.body.layer3.0.downsample.0.weight\": 524288,\n  \"backbone.0.body.layer3.1.conv1.weight\": 262144,\n  \"backbone.0.body.layer3.1.conv2.weight\": 589824,\n  \"backbone.0.body.layer3.1.conv3.weight\": 262144,\n  \"backbone.0.body.layer3.2.conv1.weight\": 262144,\n  \"backbone.0.body.layer3.2.conv2.weight\": 589824,\n  \"backbone.0.body.layer3.2.conv3.weight\": 262144,\n  \"backbone.0.body.layer3.3.conv1.weight\": 262144,\n  \"backbone.0.body.layer3.3.conv2.weight\": 589824,\n  \"backbone.0.body.layer3.3.conv3.weight\": 262144,\n  \"backbone.0.body.layer3.4.conv1.weight\": 262144,\n  \"backbone.0.body.layer3.4.conv2.weight\": 589824,\n  \"backbone.0.body.layer3.4.conv3.weight\": 262144,\n  \"backbone.0.body.layer3.5.conv1.weight\": 262144,\n  \"backbone.0.body.layer3.5.conv2.weight\": 589824,\n  \"backbone.0.body.layer3.5.conv3.weight\": 262144,\n  \"backbone.0.body.layer4.0.conv1.weight\": 524288,\n  \"backbone.0.body.layer4.0.conv2.weight\": 2359296,\n  \"backbone.0.body.layer4.0.conv3.weight\": 1048576,\n  \"backbone.0.body.layer4.0.downsample.0.weight\": 2097152,\n  \"backbone.0.body.layer4.1.conv1.weight\": 1048576,\n  \"backbone.0.body.layer4.1.conv2.weight\": 2359296,\n  \"backbone.0.body.layer4.1.conv3.weight\": 1048576,\n  \"backbone.0.body.layer4.2.conv1.weight\": 1048576,\n  \"backbone.0.body.layer4.2.conv2.weight\": 2359296,\n  \"backbone.0.body.layer4.2.conv3.weight\": 1048576\n}\ndata_aug_params: {\n  \"scales\": [\n    480,\n    512,\n    544,\n    576,\n    608,\n    640,\n    672,\n    704,\n    736,\n    768,\n    800\n  ],\n  \"max_size\": 1333,\n  \"scales2_resize\": [\n    400,\n    500,\n    600\n  ],\n  \"scales2_crop\": [\n    384,\n    600\n  ]\n}\nloading annotations into memory...\nDone (t=0.02s)\ncreating index...\nindex created!\ndata_aug_params: {\n  \"scales\": [\n    480,\n    512,\n    544,\n    576,\n    608,\n    640,\n    672,\n    704,\n    736,\n    768,\n    800\n  ],\n  \"max_size\": 1333,\n  \"scales2_resize\": [\n    400,\n    500,\n    600\n  ],\n  \"scales2_crop\": [\n    384,\n    600\n  ]\n}\nloading annotations into memory...\nDone (t=0.00s)\ncreating index...\nindex created!\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n/kaggle/working/DINO/main.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(args.resume, map_location='cpu')\n/kaggle/working/DINO/engine.py:164: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=args.amp):\n/opt/conda/lib/python3.10/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789122112/work/aten/src/ATen/native/TensorShape.cpp:3609.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\nTest:  [ 0/39]  eta: 0:00:56  class_error: 0.00  loss: 6.4885 (6.4885)  loss_bbox_dn: 0.0000 (0.0000)  loss_giou_dn: 0.0000 (0.0000)  loss_ce_dn: 0.0000 (0.0000)  loss_ce: 0.1759 (0.1759)  loss_bbox: 0.0594 (0.0594)  loss_giou: 0.6687 (0.6687)  loss_ce_0: 0.2179 (0.2179)  loss_bbox_0: 0.0551 (0.0551)  loss_giou_0: 0.6656 (0.6656)  loss_bbox_dn_0: 0.0000 (0.0000)  loss_giou_dn_0: 0.0000 (0.0000)  loss_ce_dn_0: 0.0000 (0.0000)  loss_ce_1: 0.2340 (0.2340)  loss_bbox_1: 0.0580 (0.0580)  loss_giou_1: 0.6822 (0.6822)  loss_bbox_dn_1: 0.0000 (0.0000)  loss_giou_dn_1: 0.0000 (0.0000)  loss_ce_dn_1: 0.0000 (0.0000)  loss_ce_2: 0.1965 (0.1965)  loss_bbox_2: 0.0594 (0.0594)  loss_giou_2: 0.6652 (0.6652)  loss_bbox_dn_2: 0.0000 (0.0000)  loss_giou_dn_2: 0.0000 (0.0000)  loss_ce_dn_2: 0.0000 (0.0000)  loss_ce_3: 0.1893 (0.1893)  loss_bbox_3: 0.0588 (0.0588)  loss_giou_3: 0.6612 (0.6612)  loss_bbox_dn_3: 0.0000 (0.0000)  loss_giou_dn_3: 0.0000 (0.0000)  loss_ce_dn_3: 0.0000 (0.0000)  loss_ce_4: 0.1780 (0.1780)  loss_bbox_4: 0.0594 (0.0594)  loss_giou_4: 0.6694 (0.6694)  loss_bbox_dn_4: 0.0000 (0.0000)  loss_giou_dn_4: 0.0000 (0.0000)  loss_ce_dn_4: 0.0000 (0.0000)  loss_ce_interm: 0.2291 (0.2291)  loss_bbox_interm: 0.0545 (0.0545)  loss_giou_interm: 0.6507 (0.6507)  loss_bbox_dn_unscaled: 0.0000 (0.0000)  loss_giou_dn_unscaled: 0.0000 (0.0000)  loss_ce_dn_unscaled: 0.0000 (0.0000)  loss_xy_dn_unscaled: 0.0000 (0.0000)  loss_hw_dn_unscaled: 0.0000 (0.0000)  cardinality_error_dn_unscaled: 0.0000 (0.0000)  loss_ce_unscaled: 0.1759 (0.1759)  class_error_unscaled: 0.0000 (0.0000)  loss_bbox_unscaled: 0.0119 (0.0119)  loss_giou_unscaled: 0.3344 (0.3344)  loss_xy_unscaled: 0.0030 (0.0030)  loss_hw_unscaled: 0.0089 (0.0089)  cardinality_error_unscaled: 893.0000 (893.0000)  loss_ce_0_unscaled: 0.2179 (0.2179)  loss_bbox_0_unscaled: 0.0110 (0.0110)  loss_giou_0_unscaled: 0.3328 (0.3328)  loss_xy_0_unscaled: 0.0027 (0.0027)  loss_hw_0_unscaled: 0.0083 (0.0083)  cardinality_error_0_unscaled: 893.0000 (893.0000)  loss_bbox_dn_0_unscaled: 0.0000 (0.0000)  loss_giou_dn_0_unscaled: 0.0000 (0.0000)  loss_ce_dn_0_unscaled: 0.0000 (0.0000)  loss_xy_dn_0_unscaled: 0.0000 (0.0000)  loss_hw_dn_0_unscaled: 0.0000 (0.0000)  cardinality_error_dn_0_unscaled: 0.0000 (0.0000)  loss_ce_1_unscaled: 0.2340 (0.2340)  loss_bbox_1_unscaled: 0.0116 (0.0116)  loss_giou_1_unscaled: 0.3411 (0.3411)  loss_xy_1_unscaled: 0.0030 (0.0030)  loss_hw_1_unscaled: 0.0086 (0.0086)  cardinality_error_1_unscaled: 893.0000 (893.0000)  loss_bbox_dn_1_unscaled: 0.0000 (0.0000)  loss_giou_dn_1_unscaled: 0.0000 (0.0000)  loss_ce_dn_1_unscaled: 0.0000 (0.0000)  loss_xy_dn_1_unscaled: 0.0000 (0.0000)  loss_hw_dn_1_unscaled: 0.0000 (0.0000)  cardinality_error_dn_1_unscaled: 0.0000 (0.0000)  loss_ce_2_unscaled: 0.1965 (0.1965)  loss_bbox_2_unscaled: 0.0119 (0.0119)  loss_giou_2_unscaled: 0.3326 (0.3326)  loss_xy_2_unscaled: 0.0030 (0.0030)  loss_hw_2_unscaled: 0.0089 (0.0089)  cardinality_error_2_unscaled: 893.0000 (893.0000)  loss_bbox_dn_2_unscaled: 0.0000 (0.0000)  loss_giou_dn_2_unscaled: 0.0000 (0.0000)  loss_ce_dn_2_unscaled: 0.0000 (0.0000)  loss_xy_dn_2_unscaled: 0.0000 (0.0000)  loss_hw_dn_2_unscaled: 0.0000 (0.0000)  cardinality_error_dn_2_unscaled: 0.0000 (0.0000)  loss_ce_3_unscaled: 0.1893 (0.1893)  loss_bbox_3_unscaled: 0.0118 (0.0118)  loss_giou_3_unscaled: 0.3306 (0.3306)  loss_xy_3_unscaled: 0.0029 (0.0029)  loss_hw_3_unscaled: 0.0088 (0.0088)  cardinality_error_3_unscaled: 893.0000 (893.0000)  loss_bbox_dn_3_unscaled: 0.0000 (0.0000)  loss_giou_dn_3_unscaled: 0.0000 (0.0000)  loss_ce_dn_3_unscaled: 0.0000 (0.0000)  loss_xy_dn_3_unscaled: 0.0000 (0.0000)  loss_hw_dn_3_unscaled: 0.0000 (0.0000)  cardinality_error_dn_3_unscaled: 0.0000 (0.0000)  loss_ce_4_unscaled: 0.1780 (0.1780)  loss_bbox_4_unscaled: 0.0119 (0.0119)  loss_giou_4_unscaled: 0.3347 (0.3347)  loss_xy_4_unscaled: 0.0030 (0.0030)  loss_hw_4_unscaled: 0.0089 (0.0089)  cardinality_error_4_unscaled: 893.0000 (893.0000)  loss_bbox_dn_4_unscaled: 0.0000 (0.0000)  loss_giou_dn_4_unscaled: 0.0000 (0.0000)  loss_ce_dn_4_unscaled: 0.0000 (0.0000)  loss_xy_dn_4_unscaled: 0.0000 (0.0000)  loss_hw_dn_4_unscaled: 0.0000 (0.0000)  cardinality_error_dn_4_unscaled: 0.0000 (0.0000)  loss_ce_interm_unscaled: 0.2291 (0.2291)  loss_bbox_interm_unscaled: 0.0109 (0.0109)  loss_giou_interm_unscaled: 0.3253 (0.3253)  loss_xy_interm_unscaled: 0.0026 (0.0026)  loss_hw_interm_unscaled: 0.0083 (0.0083)  cardinality_error_interm_unscaled: 893.0000 (893.0000)  time: 1.4559  data: 0.4131  max mem: 647\nTest:  [10/39]  eta: 0:00:09  class_error: 0.00  loss: 5.4543 (5.0142)  loss_bbox_dn: 0.0000 (0.0000)  loss_giou_dn: 0.0000 (0.0000)  loss_ce_dn: 0.0000 (0.0000)  loss_ce: 0.1531 (0.1374)  loss_bbox: 0.0592 (0.0601)  loss_giou: 0.5112 (0.5093)  loss_ce_0: 0.1758 (0.1537)  loss_bbox_0: 0.0613 (0.0600)  loss_giou_0: 0.5328 (0.5052)  loss_bbox_dn_0: 0.0000 (0.0000)  loss_giou_dn_0: 0.0000 (0.0000)  loss_ce_dn_0: 0.0000 (0.0000)  loss_ce_1: 0.1433 (0.1466)  loss_bbox_1: 0.0600 (0.0617)  loss_giou_1: 0.5337 (0.5151)  loss_bbox_dn_1: 0.0000 (0.0000)  loss_giou_dn_1: 0.0000 (0.0000)  loss_ce_dn_1: 0.0000 (0.0000)  loss_ce_2: 0.1343 (0.1399)  loss_bbox_2: 0.0594 (0.0612)  loss_giou_2: 0.5195 (0.5111)  loss_bbox_dn_2: 0.0000 (0.0000)  loss_giou_dn_2: 0.0000 (0.0000)  loss_ce_dn_2: 0.0000 (0.0000)  loss_ce_3: 0.1407 (0.1387)  loss_bbox_3: 0.0588 (0.0612)  loss_giou_3: 0.5409 (0.5138)  loss_bbox_dn_3: 0.0000 (0.0000)  loss_giou_dn_3: 0.0000 (0.0000)  loss_ce_dn_3: 0.0000 (0.0000)  loss_ce_4: 0.1562 (0.1408)  loss_bbox_4: 0.0593 (0.0601)  loss_giou_4: 0.5100 (0.5093)  loss_bbox_dn_4: 0.0000 (0.0000)  loss_giou_dn_4: 0.0000 (0.0000)  loss_ce_dn_4: 0.0000 (0.0000)  loss_ce_interm: 0.1574 (0.1591)  loss_bbox_interm: 0.0590 (0.0605)  loss_giou_interm: 0.5428 (0.5094)  loss_bbox_dn_unscaled: 0.0000 (0.0000)  loss_giou_dn_unscaled: 0.0000 (0.0000)  loss_ce_dn_unscaled: 0.0000 (0.0000)  loss_xy_dn_unscaled: 0.0000 (0.0000)  loss_hw_dn_unscaled: 0.0000 (0.0000)  cardinality_error_dn_unscaled: 0.0000 (0.0000)  loss_ce_unscaled: 0.1531 (0.1374)  class_error_unscaled: 0.0000 (0.0000)  loss_bbox_unscaled: 0.0118 (0.0120)  loss_giou_unscaled: 0.2556 (0.2546)  loss_xy_unscaled: 0.0041 (0.0038)  loss_hw_unscaled: 0.0085 (0.0082)  cardinality_error_unscaled: 892.0000 (887.5455)  loss_ce_0_unscaled: 0.1758 (0.1537)  loss_bbox_0_unscaled: 0.0123 (0.0120)  loss_giou_0_unscaled: 0.2664 (0.2526)  loss_xy_0_unscaled: 0.0039 (0.0039)  loss_hw_0_unscaled: 0.0083 (0.0081)  cardinality_error_0_unscaled: 892.0000 (887.5455)  loss_bbox_dn_0_unscaled: 0.0000 (0.0000)  loss_giou_dn_0_unscaled: 0.0000 (0.0000)  loss_ce_dn_0_unscaled: 0.0000 (0.0000)  loss_xy_dn_0_unscaled: 0.0000 (0.0000)  loss_hw_dn_0_unscaled: 0.0000 (0.0000)  cardinality_error_dn_0_unscaled: 0.0000 (0.0000)  loss_ce_1_unscaled: 0.1433 (0.1466)  loss_bbox_1_unscaled: 0.0120 (0.0123)  loss_giou_1_unscaled: 0.2668 (0.2575)  loss_xy_1_unscaled: 0.0040 (0.0040)  loss_hw_1_unscaled: 0.0086 (0.0083)  cardinality_error_1_unscaled: 892.0000 (887.5455)  loss_bbox_dn_1_unscaled: 0.0000 (0.0000)  loss_giou_dn_1_unscaled: 0.0000 (0.0000)  loss_ce_dn_1_unscaled: 0.0000 (0.0000)  loss_xy_dn_1_unscaled: 0.0000 (0.0000)  loss_hw_dn_1_unscaled: 0.0000 (0.0000)  cardinality_error_dn_1_unscaled: 0.0000 (0.0000)  loss_ce_2_unscaled: 0.1343 (0.1399)  loss_bbox_2_unscaled: 0.0119 (0.0122)  loss_giou_2_unscaled: 0.2597 (0.2555)  loss_xy_2_unscaled: 0.0042 (0.0039)  loss_hw_2_unscaled: 0.0085 (0.0084)  cardinality_error_2_unscaled: 892.0000 (887.5455)  loss_bbox_dn_2_unscaled: 0.0000 (0.0000)  loss_giou_dn_2_unscaled: 0.0000 (0.0000)  loss_ce_dn_2_unscaled: 0.0000 (0.0000)  loss_xy_dn_2_unscaled: 0.0000 (0.0000)  loss_hw_dn_2_unscaled: 0.0000 (0.0000)  cardinality_error_dn_2_unscaled: 0.0000 (0.0000)  loss_ce_3_unscaled: 0.1407 (0.1387)  loss_bbox_3_unscaled: 0.0118 (0.0122)  loss_giou_3_unscaled: 0.2705 (0.2569)  loss_xy_3_unscaled: 0.0041 (0.0039)  loss_hw_3_unscaled: 0.0088 (0.0083)  cardinality_error_3_unscaled: 892.0000 (887.5455)  loss_bbox_dn_3_unscaled: 0.0000 (0.0000)  loss_giou_dn_3_unscaled: 0.0000 (0.0000)  loss_ce_dn_3_unscaled: 0.0000 (0.0000)  loss_xy_dn_3_unscaled: 0.0000 (0.0000)  loss_hw_dn_3_unscaled: 0.0000 (0.0000)  cardinality_error_dn_3_unscaled: 0.0000 (0.0000)  loss_ce_4_unscaled: 0.1562 (0.1408)  loss_bbox_4_unscaled: 0.0119 (0.0120)  loss_giou_4_unscaled: 0.2550 (0.2547)  loss_xy_4_unscaled: 0.0041 (0.0038)  loss_hw_4_unscaled: 0.0085 (0.0082)  cardinality_error_4_unscaled: 892.0000 (887.5455)  loss_bbox_dn_4_unscaled: 0.0000 (0.0000)  loss_giou_dn_4_unscaled: 0.0000 (0.0000)  loss_ce_dn_4_unscaled: 0.0000 (0.0000)  loss_xy_dn_4_unscaled: 0.0000 (0.0000)  loss_hw_dn_4_unscaled: 0.0000 (0.0000)  cardinality_error_dn_4_unscaled: 0.0000 (0.0000)  loss_ce_interm_unscaled: 0.1574 (0.1591)  loss_bbox_interm_unscaled: 0.0118 (0.0121)  loss_giou_interm_unscaled: 0.2714 (0.2547)  loss_xy_interm_unscaled: 0.0043 (0.0039)  loss_hw_interm_unscaled: 0.0083 (0.0082)  cardinality_error_interm_unscaled: 892.0000 (887.5455)  time: 0.3185  data: 0.0453  max mem: 649\nTest:  [20/39]  eta: 0:00:04  class_error: 0.00  loss: 4.9708 (5.2316)  loss_bbox_dn: 0.0000 (0.0000)  loss_giou_dn: 0.0000 (0.0000)  loss_ce_dn: 0.0000 (0.0000)  loss_ce: 0.1729 (0.2151)  loss_bbox: 0.0592 (0.0695)  loss_giou: 0.4569 (0.4615)  loss_ce_0: 0.1768 (0.2224)  loss_bbox_0: 0.0641 (0.0682)  loss_giou_0: 0.4431 (0.4561)  loss_bbox_dn_0: 0.0000 (0.0000)  loss_giou_dn_0: 0.0000 (0.0000)  loss_ce_dn_0: 0.0000 (0.0000)  loss_ce_1: 0.1597 (0.2130)  loss_bbox_1: 0.0632 (0.0696)  loss_giou_1: 0.4544 (0.4627)  loss_bbox_dn_1: 0.0000 (0.0000)  loss_giou_dn_1: 0.0000 (0.0000)  loss_ce_dn_1: 0.0000 (0.0000)  loss_ce_2: 0.1772 (0.2147)  loss_bbox_2: 0.0637 (0.0696)  loss_giou_2: 0.4511 (0.4606)  loss_bbox_dn_2: 0.0000 (0.0000)  loss_giou_dn_2: 0.0000 (0.0000)  loss_ce_dn_2: 0.0000 (0.0000)  loss_ce_3: 0.1714 (0.2106)  loss_bbox_3: 0.0657 (0.0699)  loss_giou_3: 0.4591 (0.4633)  loss_bbox_dn_3: 0.0000 (0.0000)  loss_giou_dn_3: 0.0000 (0.0000)  loss_ce_dn_3: 0.0000 (0.0000)  loss_ce_4: 0.1731 (0.2137)  loss_bbox_4: 0.0593 (0.0695)  loss_giou_4: 0.4564 (0.4617)  loss_bbox_dn_4: 0.0000 (0.0000)  loss_giou_dn_4: 0.0000 (0.0000)  loss_ce_dn_4: 0.0000 (0.0000)  loss_ce_interm: 0.1637 (0.2219)  loss_bbox_interm: 0.0659 (0.0715)  loss_giou_interm: 0.4414 (0.4664)  loss_bbox_dn_unscaled: 0.0000 (0.0000)  loss_giou_dn_unscaled: 0.0000 (0.0000)  loss_ce_dn_unscaled: 0.0000 (0.0000)  loss_xy_dn_unscaled: 0.0000 (0.0000)  loss_hw_dn_unscaled: 0.0000 (0.0000)  cardinality_error_dn_unscaled: 0.0000 (0.0000)  loss_ce_unscaled: 0.1729 (0.2151)  class_error_unscaled: 0.0000 (0.0000)  loss_bbox_unscaled: 0.0118 (0.0139)  loss_giou_unscaled: 0.2284 (0.2308)  loss_xy_unscaled: 0.0042 (0.0048)  loss_hw_unscaled: 0.0085 (0.0091)  cardinality_error_unscaled: 895.0000 (891.2381)  loss_ce_0_unscaled: 0.1768 (0.2224)  loss_bbox_0_unscaled: 0.0128 (0.0136)  loss_giou_0_unscaled: 0.2216 (0.2280)  loss_xy_0_unscaled: 0.0044 (0.0049)  loss_hw_0_unscaled: 0.0084 (0.0088)  cardinality_error_0_unscaled: 895.0000 (891.2381)  loss_bbox_dn_0_unscaled: 0.0000 (0.0000)  loss_giou_dn_0_unscaled: 0.0000 (0.0000)  loss_ce_dn_0_unscaled: 0.0000 (0.0000)  loss_xy_dn_0_unscaled: 0.0000 (0.0000)  loss_hw_dn_0_unscaled: 0.0000 (0.0000)  cardinality_error_dn_0_unscaled: 0.0000 (0.0000)  loss_ce_1_unscaled: 0.1597 (0.2130)  loss_bbox_1_unscaled: 0.0126 (0.0139)  loss_giou_1_unscaled: 0.2272 (0.2313)  loss_xy_1_unscaled: 0.0044 (0.0049)  loss_hw_1_unscaled: 0.0086 (0.0090)  cardinality_error_1_unscaled: 895.0000 (891.2381)  loss_bbox_dn_1_unscaled: 0.0000 (0.0000)  loss_giou_dn_1_unscaled: 0.0000 (0.0000)  loss_ce_dn_1_unscaled: 0.0000 (0.0000)  loss_xy_dn_1_unscaled: 0.0000 (0.0000)  loss_hw_dn_1_unscaled: 0.0000 (0.0000)  cardinality_error_dn_1_unscaled: 0.0000 (0.0000)  loss_ce_2_unscaled: 0.1772 (0.2147)  loss_bbox_2_unscaled: 0.0127 (0.0139)  loss_giou_2_unscaled: 0.2256 (0.2303)  loss_xy_2_unscaled: 0.0042 (0.0048)  loss_hw_2_unscaled: 0.0085 (0.0091)  cardinality_error_2_unscaled: 895.0000 (891.2381)  loss_bbox_dn_2_unscaled: 0.0000 (0.0000)  loss_giou_dn_2_unscaled: 0.0000 (0.0000)  loss_ce_dn_2_unscaled: 0.0000 (0.0000)  loss_xy_dn_2_unscaled: 0.0000 (0.0000)  loss_hw_dn_2_unscaled: 0.0000 (0.0000)  cardinality_error_dn_2_unscaled: 0.0000 (0.0000)  loss_ce_3_unscaled: 0.1714 (0.2106)  loss_bbox_3_unscaled: 0.0131 (0.0140)  loss_giou_3_unscaled: 0.2296 (0.2316)  loss_xy_3_unscaled: 0.0042 (0.0049)  loss_hw_3_unscaled: 0.0088 (0.0091)  cardinality_error_3_unscaled: 895.0000 (891.2381)  loss_bbox_dn_3_unscaled: 0.0000 (0.0000)  loss_giou_dn_3_unscaled: 0.0000 (0.0000)  loss_ce_dn_3_unscaled: 0.0000 (0.0000)  loss_xy_dn_3_unscaled: 0.0000 (0.0000)  loss_hw_dn_3_unscaled: 0.0000 (0.0000)  cardinality_error_dn_3_unscaled: 0.0000 (0.0000)  loss_ce_4_unscaled: 0.1731 (0.2137)  loss_bbox_4_unscaled: 0.0119 (0.0139)  loss_giou_4_unscaled: 0.2282 (0.2308)  loss_xy_4_unscaled: 0.0042 (0.0048)  loss_hw_4_unscaled: 0.0085 (0.0091)  cardinality_error_4_unscaled: 895.0000 (891.2381)  loss_bbox_dn_4_unscaled: 0.0000 (0.0000)  loss_giou_dn_4_unscaled: 0.0000 (0.0000)  loss_ce_dn_4_unscaled: 0.0000 (0.0000)  loss_xy_dn_4_unscaled: 0.0000 (0.0000)  loss_hw_dn_4_unscaled: 0.0000 (0.0000)  cardinality_error_dn_4_unscaled: 0.0000 (0.0000)  loss_ce_interm_unscaled: 0.1637 (0.2219)  loss_bbox_interm_unscaled: 0.0132 (0.0143)  loss_giou_interm_unscaled: 0.2207 (0.2332)  loss_xy_interm_unscaled: 0.0054 (0.0049)  loss_hw_interm_unscaled: 0.0082 (0.0094)  cardinality_error_interm_unscaled: 895.0000 (891.2381)  time: 0.1922  data: 0.0062  max mem: 649\nTest:  [30/39]  eta: 0:00:02  class_error: 0.00  loss: 5.2744 (5.5276)  loss_bbox_dn: 0.0000 (0.0000)  loss_giou_dn: 0.0000 (0.0000)  loss_ce_dn: 0.0000 (0.0000)  loss_ce: 0.2571 (0.2209)  loss_bbox: 0.0895 (0.0973)  loss_giou: 0.4289 (0.4743)  loss_ce_0: 0.2211 (0.2229)  loss_bbox_0: 0.0869 (0.0964)  loss_giou_0: 0.4328 (0.4678)  loss_bbox_dn_0: 0.0000 (0.0000)  loss_giou_dn_0: 0.0000 (0.0000)  loss_ce_dn_0: 0.0000 (0.0000)  loss_ce_1: 0.2213 (0.2149)  loss_bbox_1: 0.0885 (0.0972)  loss_giou_1: 0.4222 (0.4733)  loss_bbox_dn_1: 0.0000 (0.0000)  loss_giou_dn_1: 0.0000 (0.0000)  loss_ce_dn_1: 0.0000 (0.0000)  loss_ce_2: 0.2312 (0.2182)  loss_bbox_2: 0.0853 (0.0968)  loss_giou_2: 0.4296 (0.4732)  loss_bbox_dn_2: 0.0000 (0.0000)  loss_giou_dn_2: 0.0000 (0.0000)  loss_ce_dn_2: 0.0000 (0.0000)  loss_ce_3: 0.2442 (0.2150)  loss_bbox_3: 0.0894 (0.0974)  loss_giou_3: 0.4262 (0.4755)  loss_bbox_dn_3: 0.0000 (0.0000)  loss_giou_dn_3: 0.0000 (0.0000)  loss_ce_dn_3: 0.0000 (0.0000)  loss_ce_4: 0.2373 (0.2195)  loss_bbox_4: 0.0895 (0.0973)  loss_giou_4: 0.4301 (0.4746)  loss_bbox_dn_4: 0.0000 (0.0000)  loss_giou_dn_4: 0.0000 (0.0000)  loss_ce_dn_4: 0.0000 (0.0000)  loss_ce_interm: 0.2150 (0.2232)  loss_bbox_interm: 0.0888 (0.0976)  loss_giou_interm: 0.3823 (0.4745)  loss_bbox_dn_unscaled: 0.0000 (0.0000)  loss_giou_dn_unscaled: 0.0000 (0.0000)  loss_ce_dn_unscaled: 0.0000 (0.0000)  loss_xy_dn_unscaled: 0.0000 (0.0000)  loss_hw_dn_unscaled: 0.0000 (0.0000)  cardinality_error_dn_unscaled: 0.0000 (0.0000)  loss_ce_unscaled: 0.2571 (0.2209)  class_error_unscaled: 0.0000 (0.6452)  loss_bbox_unscaled: 0.0179 (0.0195)  loss_giou_unscaled: 0.2144 (0.2371)  loss_xy_unscaled: 0.0059 (0.0062)  loss_hw_unscaled: 0.0138 (0.0132)  cardinality_error_unscaled: 895.0000 (892.2581)  loss_ce_0_unscaled: 0.2211 (0.2229)  loss_bbox_0_unscaled: 0.0174 (0.0193)  loss_giou_0_unscaled: 0.2164 (0.2339)  loss_xy_0_unscaled: 0.0060 (0.0062)  loss_hw_0_unscaled: 0.0125 (0.0131)  cardinality_error_0_unscaled: 895.0000 (892.2581)  loss_bbox_dn_0_unscaled: 0.0000 (0.0000)  loss_giou_dn_0_unscaled: 0.0000 (0.0000)  loss_ce_dn_0_unscaled: 0.0000 (0.0000)  loss_xy_dn_0_unscaled: 0.0000 (0.0000)  loss_hw_dn_0_unscaled: 0.0000 (0.0000)  cardinality_error_dn_0_unscaled: 0.0000 (0.0000)  loss_ce_1_unscaled: 0.2213 (0.2149)  loss_bbox_1_unscaled: 0.0177 (0.0194)  loss_giou_1_unscaled: 0.2111 (0.2367)  loss_xy_1_unscaled: 0.0054 (0.0062)  loss_hw_1_unscaled: 0.0129 (0.0132)  cardinality_error_1_unscaled: 895.0000 (892.2581)  loss_bbox_dn_1_unscaled: 0.0000 (0.0000)  loss_giou_dn_1_unscaled: 0.0000 (0.0000)  loss_ce_dn_1_unscaled: 0.0000 (0.0000)  loss_xy_dn_1_unscaled: 0.0000 (0.0000)  loss_hw_dn_1_unscaled: 0.0000 (0.0000)  cardinality_error_dn_1_unscaled: 0.0000 (0.0000)  loss_ce_2_unscaled: 0.2312 (0.2182)  loss_bbox_2_unscaled: 0.0171 (0.0194)  loss_giou_2_unscaled: 0.2148 (0.2366)  loss_xy_2_unscaled: 0.0059 (0.0062)  loss_hw_2_unscaled: 0.0134 (0.0132)  cardinality_error_2_unscaled: 895.0000 (892.2581)  loss_bbox_dn_2_unscaled: 0.0000 (0.0000)  loss_giou_dn_2_unscaled: 0.0000 (0.0000)  loss_ce_dn_2_unscaled: 0.0000 (0.0000)  loss_xy_dn_2_unscaled: 0.0000 (0.0000)  loss_hw_dn_2_unscaled: 0.0000 (0.0000)  cardinality_error_dn_2_unscaled: 0.0000 (0.0000)  loss_ce_3_unscaled: 0.2442 (0.2150)  loss_bbox_3_unscaled: 0.0179 (0.0195)  loss_giou_3_unscaled: 0.2131 (0.2377)  loss_xy_3_unscaled: 0.0059 (0.0062)  loss_hw_3_unscaled: 0.0136 (0.0133)  cardinality_error_3_unscaled: 895.0000 (892.2581)  loss_bbox_dn_3_unscaled: 0.0000 (0.0000)  loss_giou_dn_3_unscaled: 0.0000 (0.0000)  loss_ce_dn_3_unscaled: 0.0000 (0.0000)  loss_xy_dn_3_unscaled: 0.0000 (0.0000)  loss_hw_dn_3_unscaled: 0.0000 (0.0000)  cardinality_error_dn_3_unscaled: 0.0000 (0.0000)  loss_ce_4_unscaled: 0.2373 (0.2195)  loss_bbox_4_unscaled: 0.0179 (0.0195)  loss_giou_4_unscaled: 0.2151 (0.2373)  loss_xy_4_unscaled: 0.0059 (0.0062)  loss_hw_4_unscaled: 0.0138 (0.0133)  cardinality_error_4_unscaled: 895.0000 (892.2581)  loss_bbox_dn_4_unscaled: 0.0000 (0.0000)  loss_giou_dn_4_unscaled: 0.0000 (0.0000)  loss_ce_dn_4_unscaled: 0.0000 (0.0000)  loss_xy_dn_4_unscaled: 0.0000 (0.0000)  loss_hw_dn_4_unscaled: 0.0000 (0.0000)  cardinality_error_dn_4_unscaled: 0.0000 (0.0000)  loss_ce_interm_unscaled: 0.2150 (0.2232)  loss_bbox_interm_unscaled: 0.0178 (0.0195)  loss_giou_interm_unscaled: 0.1912 (0.2373)  loss_xy_interm_unscaled: 0.0054 (0.0062)  loss_hw_interm_unscaled: 0.0129 (0.0133)  cardinality_error_interm_unscaled: 895.0000 (892.2581)  time: 0.1816  data: 0.0053  max mem: 649\nTest:  [38/39]  eta: 0:00:00  class_error: 0.00  loss: 5.4705 (5.7111)  loss_bbox_dn: 0.0000 (0.0000)  loss_giou_dn: 0.0000 (0.0000)  loss_ce_dn: 0.0000 (0.0000)  loss_ce: 0.3014 (0.2625)  loss_bbox: 0.0895 (0.0940)  loss_giou: 0.4646 (0.4678)  loss_ce_0: 0.2527 (0.2544)  loss_bbox_0: 0.0880 (0.0935)  loss_giou_0: 0.4431 (0.4621)  loss_bbox_dn_0: 0.0000 (0.0000)  loss_giou_dn_0: 0.0000 (0.0000)  loss_ce_dn_0: 0.0000 (0.0000)  loss_ce_1: 0.2672 (0.2484)  loss_bbox_1: 0.0830 (0.0937)  loss_giou_1: 0.4544 (0.4683)  loss_bbox_dn_1: 0.0000 (0.0000)  loss_giou_dn_1: 0.0000 (0.0000)  loss_ce_dn_1: 0.0000 (0.0000)  loss_ce_2: 0.2650 (0.2530)  loss_bbox_2: 0.0853 (0.0932)  loss_giou_2: 0.4641 (0.4646)  loss_bbox_dn_2: 0.0000 (0.0000)  loss_giou_dn_2: 0.0000 (0.0000)  loss_ce_dn_2: 0.0000 (0.0000)  loss_ce_3: 0.2768 (0.2549)  loss_bbox_3: 0.0894 (0.0943)  loss_giou_3: 0.4604 (0.4690)  loss_bbox_dn_3: 0.0000 (0.0000)  loss_giou_dn_3: 0.0000 (0.0000)  loss_ce_dn_3: 0.0000 (0.0000)  loss_ce_4: 0.2847 (0.2631)  loss_bbox_4: 0.0895 (0.0938)  loss_giou_4: 0.4666 (0.4656)  loss_bbox_dn_4: 0.0000 (0.0000)  loss_giou_dn_4: 0.0000 (0.0000)  loss_ce_dn_4: 0.0000 (0.0000)  loss_ce_interm: 0.2679 (0.2470)  loss_bbox_interm: 0.0972 (0.0980)  loss_giou_interm: 0.4287 (0.4699)  loss_bbox_dn_unscaled: 0.0000 (0.0000)  loss_giou_dn_unscaled: 0.0000 (0.0000)  loss_ce_dn_unscaled: 0.0000 (0.0000)  loss_xy_dn_unscaled: 0.0000 (0.0000)  loss_hw_dn_unscaled: 0.0000 (0.0000)  cardinality_error_dn_unscaled: 0.0000 (0.0000)  loss_ce_unscaled: 0.3014 (0.2625)  class_error_unscaled: 0.0000 (0.5128)  loss_bbox_unscaled: 0.0179 (0.0188)  loss_giou_unscaled: 0.2323 (0.2339)  loss_xy_unscaled: 0.0053 (0.0060)  loss_hw_unscaled: 0.0133 (0.0128)  cardinality_error_unscaled: 895.0000 (892.6667)  loss_ce_0_unscaled: 0.2527 (0.2544)  loss_bbox_0_unscaled: 0.0176 (0.0187)  loss_giou_0_unscaled: 0.2216 (0.2311)  loss_xy_0_unscaled: 0.0051 (0.0059)  loss_hw_0_unscaled: 0.0125 (0.0128)  cardinality_error_0_unscaled: 895.0000 (892.6667)  loss_bbox_dn_0_unscaled: 0.0000 (0.0000)  loss_giou_dn_0_unscaled: 0.0000 (0.0000)  loss_ce_dn_0_unscaled: 0.0000 (0.0000)  loss_xy_dn_0_unscaled: 0.0000 (0.0000)  loss_hw_dn_0_unscaled: 0.0000 (0.0000)  cardinality_error_dn_0_unscaled: 0.0000 (0.0000)  loss_ce_1_unscaled: 0.2672 (0.2484)  loss_bbox_1_unscaled: 0.0166 (0.0187)  loss_giou_1_unscaled: 0.2272 (0.2341)  loss_xy_1_unscaled: 0.0048 (0.0060)  loss_hw_1_unscaled: 0.0129 (0.0128)  cardinality_error_1_unscaled: 895.0000 (892.6667)  loss_bbox_dn_1_unscaled: 0.0000 (0.0000)  loss_giou_dn_1_unscaled: 0.0000 (0.0000)  loss_ce_dn_1_unscaled: 0.0000 (0.0000)  loss_xy_dn_1_unscaled: 0.0000 (0.0000)  loss_hw_dn_1_unscaled: 0.0000 (0.0000)  cardinality_error_dn_1_unscaled: 0.0000 (0.0000)  loss_ce_2_unscaled: 0.2650 (0.2530)  loss_bbox_2_unscaled: 0.0171 (0.0186)  loss_giou_2_unscaled: 0.2320 (0.2323)  loss_xy_2_unscaled: 0.0052 (0.0059)  loss_hw_2_unscaled: 0.0134 (0.0127)  cardinality_error_2_unscaled: 895.0000 (892.6667)  loss_bbox_dn_2_unscaled: 0.0000 (0.0000)  loss_giou_dn_2_unscaled: 0.0000 (0.0000)  loss_ce_dn_2_unscaled: 0.0000 (0.0000)  loss_xy_dn_2_unscaled: 0.0000 (0.0000)  loss_hw_dn_2_unscaled: 0.0000 (0.0000)  cardinality_error_dn_2_unscaled: 0.0000 (0.0000)  loss_ce_3_unscaled: 0.2768 (0.2549)  loss_bbox_3_unscaled: 0.0179 (0.0189)  loss_giou_3_unscaled: 0.2302 (0.2345)  loss_xy_3_unscaled: 0.0053 (0.0060)  loss_hw_3_unscaled: 0.0136 (0.0129)  cardinality_error_3_unscaled: 895.0000 (892.6667)  loss_bbox_dn_3_unscaled: 0.0000 (0.0000)  loss_giou_dn_3_unscaled: 0.0000 (0.0000)  loss_ce_dn_3_unscaled: 0.0000 (0.0000)  loss_xy_dn_3_unscaled: 0.0000 (0.0000)  loss_hw_dn_3_unscaled: 0.0000 (0.0000)  cardinality_error_dn_3_unscaled: 0.0000 (0.0000)  loss_ce_4_unscaled: 0.2847 (0.2631)  loss_bbox_4_unscaled: 0.0179 (0.0188)  loss_giou_4_unscaled: 0.2333 (0.2328)  loss_xy_4_unscaled: 0.0053 (0.0060)  loss_hw_4_unscaled: 0.0135 (0.0128)  cardinality_error_4_unscaled: 895.0000 (892.6667)  loss_bbox_dn_4_unscaled: 0.0000 (0.0000)  loss_giou_dn_4_unscaled: 0.0000 (0.0000)  loss_ce_dn_4_unscaled: 0.0000 (0.0000)  loss_xy_dn_4_unscaled: 0.0000 (0.0000)  loss_hw_dn_4_unscaled: 0.0000 (0.0000)  cardinality_error_dn_4_unscaled: 0.0000 (0.0000)  loss_ce_interm_unscaled: 0.2679 (0.2470)  loss_bbox_interm_unscaled: 0.0194 (0.0196)  loss_giou_interm_unscaled: 0.2143 (0.2350)  loss_xy_interm_unscaled: 0.0054 (0.0061)  loss_hw_interm_unscaled: 0.0134 (0.0135)  cardinality_error_interm_unscaled: 895.0000 (892.6667)  time: 0.1831  data: 0.0062  max mem: 649\nTest: Total time: 0:00:08 (0.2237 s / it)\nAveraged stats: class_error: 0.00  loss: 5.4705 (5.7111)  loss_bbox_dn: 0.0000 (0.0000)  loss_giou_dn: 0.0000 (0.0000)  loss_ce_dn: 0.0000 (0.0000)  loss_ce: 0.3014 (0.2625)  loss_bbox: 0.0895 (0.0940)  loss_giou: 0.4646 (0.4678)  loss_ce_0: 0.2527 (0.2544)  loss_bbox_0: 0.0880 (0.0935)  loss_giou_0: 0.4431 (0.4621)  loss_bbox_dn_0: 0.0000 (0.0000)  loss_giou_dn_0: 0.0000 (0.0000)  loss_ce_dn_0: 0.0000 (0.0000)  loss_ce_1: 0.2672 (0.2484)  loss_bbox_1: 0.0830 (0.0937)  loss_giou_1: 0.4544 (0.4683)  loss_bbox_dn_1: 0.0000 (0.0000)  loss_giou_dn_1: 0.0000 (0.0000)  loss_ce_dn_1: 0.0000 (0.0000)  loss_ce_2: 0.2650 (0.2530)  loss_bbox_2: 0.0853 (0.0932)  loss_giou_2: 0.4641 (0.4646)  loss_bbox_dn_2: 0.0000 (0.0000)  loss_giou_dn_2: 0.0000 (0.0000)  loss_ce_dn_2: 0.0000 (0.0000)  loss_ce_3: 0.2768 (0.2549)  loss_bbox_3: 0.0894 (0.0943)  loss_giou_3: 0.4604 (0.4690)  loss_bbox_dn_3: 0.0000 (0.0000)  loss_giou_dn_3: 0.0000 (0.0000)  loss_ce_dn_3: 0.0000 (0.0000)  loss_ce_4: 0.2847 (0.2631)  loss_bbox_4: 0.0895 (0.0938)  loss_giou_4: 0.4666 (0.4656)  loss_bbox_dn_4: 0.0000 (0.0000)  loss_giou_dn_4: 0.0000 (0.0000)  loss_ce_dn_4: 0.0000 (0.0000)  loss_ce_interm: 0.2679 (0.2470)  loss_bbox_interm: 0.0972 (0.0980)  loss_giou_interm: 0.4287 (0.4699)  loss_bbox_dn_unscaled: 0.0000 (0.0000)  loss_giou_dn_unscaled: 0.0000 (0.0000)  loss_ce_dn_unscaled: 0.0000 (0.0000)  loss_xy_dn_unscaled: 0.0000 (0.0000)  loss_hw_dn_unscaled: 0.0000 (0.0000)  cardinality_error_dn_unscaled: 0.0000 (0.0000)  loss_ce_unscaled: 0.3014 (0.2625)  class_error_unscaled: 0.0000 (0.5128)  loss_bbox_unscaled: 0.0179 (0.0188)  loss_giou_unscaled: 0.2323 (0.2339)  loss_xy_unscaled: 0.0053 (0.0060)  loss_hw_unscaled: 0.0133 (0.0128)  cardinality_error_unscaled: 895.0000 (892.6667)  loss_ce_0_unscaled: 0.2527 (0.2544)  loss_bbox_0_unscaled: 0.0176 (0.0187)  loss_giou_0_unscaled: 0.2216 (0.2311)  loss_xy_0_unscaled: 0.0051 (0.0059)  loss_hw_0_unscaled: 0.0125 (0.0128)  cardinality_error_0_unscaled: 895.0000 (892.6667)  loss_bbox_dn_0_unscaled: 0.0000 (0.0000)  loss_giou_dn_0_unscaled: 0.0000 (0.0000)  loss_ce_dn_0_unscaled: 0.0000 (0.0000)  loss_xy_dn_0_unscaled: 0.0000 (0.0000)  loss_hw_dn_0_unscaled: 0.0000 (0.0000)  cardinality_error_dn_0_unscaled: 0.0000 (0.0000)  loss_ce_1_unscaled: 0.2672 (0.2484)  loss_bbox_1_unscaled: 0.0166 (0.0187)  loss_giou_1_unscaled: 0.2272 (0.2341)  loss_xy_1_unscaled: 0.0048 (0.0060)  loss_hw_1_unscaled: 0.0129 (0.0128)  cardinality_error_1_unscaled: 895.0000 (892.6667)  loss_bbox_dn_1_unscaled: 0.0000 (0.0000)  loss_giou_dn_1_unscaled: 0.0000 (0.0000)  loss_ce_dn_1_unscaled: 0.0000 (0.0000)  loss_xy_dn_1_unscaled: 0.0000 (0.0000)  loss_hw_dn_1_unscaled: 0.0000 (0.0000)  cardinality_error_dn_1_unscaled: 0.0000 (0.0000)  loss_ce_2_unscaled: 0.2650 (0.2530)  loss_bbox_2_unscaled: 0.0171 (0.0186)  loss_giou_2_unscaled: 0.2320 (0.2323)  loss_xy_2_unscaled: 0.0052 (0.0059)  loss_hw_2_unscaled: 0.0134 (0.0127)  cardinality_error_2_unscaled: 895.0000 (892.6667)  loss_bbox_dn_2_unscaled: 0.0000 (0.0000)  loss_giou_dn_2_unscaled: 0.0000 (0.0000)  loss_ce_dn_2_unscaled: 0.0000 (0.0000)  loss_xy_dn_2_unscaled: 0.0000 (0.0000)  loss_hw_dn_2_unscaled: 0.0000 (0.0000)  cardinality_error_dn_2_unscaled: 0.0000 (0.0000)  loss_ce_3_unscaled: 0.2768 (0.2549)  loss_bbox_3_unscaled: 0.0179 (0.0189)  loss_giou_3_unscaled: 0.2302 (0.2345)  loss_xy_3_unscaled: 0.0053 (0.0060)  loss_hw_3_unscaled: 0.0136 (0.0129)  cardinality_error_3_unscaled: 895.0000 (892.6667)  loss_bbox_dn_3_unscaled: 0.0000 (0.0000)  loss_giou_dn_3_unscaled: 0.0000 (0.0000)  loss_ce_dn_3_unscaled: 0.0000 (0.0000)  loss_xy_dn_3_unscaled: 0.0000 (0.0000)  loss_hw_dn_3_unscaled: 0.0000 (0.0000)  cardinality_error_dn_3_unscaled: 0.0000 (0.0000)  loss_ce_4_unscaled: 0.2847 (0.2631)  loss_bbox_4_unscaled: 0.0179 (0.0188)  loss_giou_4_unscaled: 0.2333 (0.2328)  loss_xy_4_unscaled: 0.0053 (0.0060)  loss_hw_4_unscaled: 0.0135 (0.0128)  cardinality_error_4_unscaled: 895.0000 (892.6667)  loss_bbox_dn_4_unscaled: 0.0000 (0.0000)  loss_giou_dn_4_unscaled: 0.0000 (0.0000)  loss_ce_dn_4_unscaled: 0.0000 (0.0000)  loss_xy_dn_4_unscaled: 0.0000 (0.0000)  loss_hw_dn_4_unscaled: 0.0000 (0.0000)  cardinality_error_dn_4_unscaled: 0.0000 (0.0000)  loss_ce_interm_unscaled: 0.2679 (0.2470)  loss_bbox_interm_unscaled: 0.0194 (0.0196)  loss_giou_interm_unscaled: 0.2143 (0.2350)  loss_xy_interm_unscaled: 0.0054 (0.0061)  loss_hw_interm_unscaled: 0.0134 (0.0135)  cardinality_error_interm_unscaled: 895.0000 (892.6667)\nAccumulating evaluation results...\nDONE (t=0.05s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.832\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.534\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.394\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.718\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.099\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.471\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.595\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.514\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.717\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805\n","output_type":"stream"}]},{"cell_type":"code","source":"# AP values obtained from the evaluation\nap_values = {\n    'AP IoU=0.50:0.95': 0.496,\n    'AP IoU=0.50': 0.832,\n    'AP IoU=0.75': 0.534,\n    'AP (small area)': 0.394,\n    'AP (medium area)': 0.633,\n    'AP (large area)': 0.718,\n}\n\n# Create a DataFrame for better visualization\nap_df = pd.DataFrame(list(ap_values.items()), columns=['Metric', 'Value'])\nprint(ap_df)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:13:17.072806Z","iopub.execute_input":"2024-09-24T11:13:17.073727Z","iopub.status.idle":"2024-09-24T11:13:17.095022Z","shell.execute_reply.started":"2024-09-24T11:13:17.073675Z","shell.execute_reply":"2024-09-24T11:13:17.094046Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"             Metric  Value\n0  AP IoU=0.50:0.95  0.496\n1       AP IoU=0.50  0.832\n2       AP IoU=0.75  0.534\n3   AP (small area)  0.394\n4  AP (medium area)  0.633\n5   AP (large area)  0.718\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade torch torchvision\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T11:46:49.190486Z","iopub.execute_input":"2024-09-24T11:46:49.190898Z","iopub.status.idle":"2024-09-24T11:48:59.774598Z","shell.execute_reply.started":"2024-09-24T11:46:49.190860Z","shell.execute_reply":"2024-09-24T11:48:59.773335Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nCollecting torch\n  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\nCollecting torchvision\n  Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch) (3.0.0)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.0\n    Uninstalling torch-2.4.0:\n      Successfully uninstalled torch-2.4.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.19.0\n    Uninstalling torchvision-0.19.0:\n      Successfully uninstalled torchvision-0.19.0\nSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 torch-2.4.1 torchvision-0.19.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from models.dino import build_dino_model","metadata":{"execution":{"iopub.status.busy":"2024-09-24T12:18:03.527097Z","iopub.execute_input":"2024-09-24T12:18:03.527499Z","iopub.status.idle":"2024-09-24T12:18:03.822196Z","shell.execute_reply.started":"2024-09-24T12:18:03.527461Z","shell.execute_reply":"2024-09-24T12:18:03.820881Z"},"trusted":true},"execution_count":127,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[127], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdino\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_dino_model\n","File \u001b[0;32m/kaggle/working/DINO/models/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# DINO\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2022 IDEA. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 [see LICENSE for details]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdino\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_dino\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(args):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m build(args)\n","File \u001b[0;32m/kaggle/working/DINO/models/dino/__init__.py:10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Conditional DETR\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2021 Microsoft. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdino\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_dino\n","File \u001b[0;32m/kaggle/working/DINO/models/dino/dino.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboxes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nms\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m box_ops\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (NestedTensor, nested_tensor_from_tensor_list,\n\u001b[1;32m     26\u001b[0m                        accuracy, get_world_size, interpolate,\n\u001b[1;32m     27\u001b[0m                        is_dist_avail_and_initialized, inverse_sigmoid)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/__init__.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/_meta_registrations.py:26\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129;43m@register_meta\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroi_align\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mmeta_roi_align\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrois must have shape as Tensor[K, 5]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/_meta_registrations.py:18\u001b[0m, in \u001b[0;36mregister_meta.<locals>.wrapper\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(fn):\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[38;5;241m.\u001b[39m_has_ops():\n\u001b[1;32m     19\u001b[0m         get_meta_lib()\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mtorchvision, op_name), overload_name), fn)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\n","\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)"],"ename":"AttributeError","evalue":"partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)","output_type":"error"}]},{"cell_type":"code","source":"# Directories for images and annotations\nval_images_dir = \"/kaggle/input/pedestrian-dataset/coco2017/val2017\"\nannotations_dir = \"/kaggle/input/pedestrian-dataset/coco2017/annotations\"\n\n# Load the COCO-style annotations\nwith open(os.path.join(annotations_dir, 'instances_val2017.json')) as f:\n    val_data = json.load(f)\n\n# Load your DINO model (update with your actual model loading logic)\nfrom models.dino import build_dino_model  # Adjust import as per your structure\nmodel = build_dino_model()\ncheckpoint = torch.load('/kaggle/input/dino_4scale/other/default/1/checkpoint0011_4scale.pth')\nmodel.load_state_dict(checkpoint)\nmodel.eval()  # Set the model to evaluation mode\nmodel.to(device)  # Move model to GPU\n\n# Prepare an empty list to hold predictions\nresults = []\n\n# Loop through each validation image\nfor img in val_data['images']:\n    image_id = img['id']\n    img_path = os.path.join(val_images_dir, img['file_name'])\n    \n    # Load the image\n    image = cv2.imread(img_path)\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    # Preprocess the image (resizing, normalization, etc.)\n    input_image = cv2.resize(image_rgb, (640, 640))  # Adjust to DINO input size if necessary\n    input_image = np.transpose(input_image, (2, 0, 1))  # Change to (C, H, W)\n    input_image = input_image / 255.0  # Normalize to [0, 1]\n    input_tensor = torch.tensor(input_image, dtype=torch.float32).unsqueeze(0).to(device)  # Add batch dimension\n\n    # Perform inference\n    with torch.no_grad():\n        outputs = model(input_tensor)  # Get model predictions\n        # Assuming outputs contains 'boxes' and 'scores' in a compatible format\n        boxes = outputs['boxes'].cpu().numpy()\n        scores = outputs['scores'].cpu().numpy()\n\n    # Threshold for predictions\n    threshold = 0.5\n    for i, score in enumerate(scores):\n        if score > threshold:\n            x1, y1, x2, y2 = boxes[i]  # Adjust based on your box output format\n            width = x2 - x1\n            height = y2 - y1\n            results.append({\n                'image_id': image_id,\n                'bbox': [x1, y1, width, height],\n                'score': score\n            })\n\n# Function to visualize detections\ndef visualize_detections(image_id, predictions, ground_truths, img_dir):\n    # Load the image\n    image_path = os.path.join(img_dir, image_id)\n    image = cv2.imread(image_path)\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    # Draw ground truth boxes in green\n    for gt in ground_truths:\n        if gt['image_id'] == image_id:\n            x, y, w, h = gt['bbox']\n            cv2.rectangle(image_rgb, (int(x), int(y)), (int(x + w), int(y + h)), (0, 255, 0), 2)\n\n    # Draw predicted boxes in red\n    for pred in predictions:\n        if pred['image_id'] == image_id:\n            x, y, w, h = pred['bbox']\n            cv2.rectangle(image_rgb, (int(x), int(y)), (int(x + w), int(y + h)), (255, 0, 0), 2)\n\n    plt.figure(figsize=(10, 10))\n    plt.imshow(image_rgb)\n    plt.axis('off')\n    plt.title(f\"Detections for {image_id}\")\n    plt.show()\n\n# Visualize detection results for a few random images\nsample_images = random.sample(val_data['images'], 5)  # Get 5 random images from the validation set\n\nfor img in sample_images:\n    image_id = img['file_name']\n    ground_truths = [ann for ann in val_data['annotations'] if ann['image_id'] == img['id']]\n    predictions_for_image = [pred for pred in results if pred['image_id'] == img['id']]\n    \n    visualize_detections(image_id, predictions_for_image, ground_truths, val_images_dir)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T12:17:48.582331Z","iopub.execute_input":"2024-09-24T12:17:48.582704Z","iopub.status.idle":"2024-09-24T12:17:48.920853Z","shell.execute_reply.started":"2024-09-24T12:17:48.582671Z","shell.execute_reply":"2024-09-24T12:17:48.919415Z"},"trusted":true},"execution_count":126,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[126], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     val_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load your DINO model (update with your actual model loading logic)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdino\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_dino_model  \u001b[38;5;66;03m# Adjust import as per your structure\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m build_dino_model()\n\u001b[1;32m     12\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/dino_4scale/other/default/1/checkpoint0011_4scale.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/kaggle/working/DINO/models/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# DINO\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2022 IDEA. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 [see LICENSE for details]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdino\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_dino\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(args):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m build(args)\n","File \u001b[0;32m/kaggle/working/DINO/models/dino/__init__.py:10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Conditional DETR\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2021 Microsoft. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdino\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_dino\n","File \u001b[0;32m/kaggle/working/DINO/models/dino/dino.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboxes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nms\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m box_ops\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (NestedTensor, nested_tensor_from_tensor_list,\n\u001b[1;32m     26\u001b[0m                        accuracy, get_world_size, interpolate,\n\u001b[1;32m     27\u001b[0m                        is_dist_avail_and_initialized, inverse_sigmoid)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/__init__.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/_meta_registrations.py:26\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129;43m@register_meta\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroi_align\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mmeta_roi_align\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrois must have shape as Tensor[K, 5]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/_meta_registrations.py:18\u001b[0m, in \u001b[0;36mregister_meta.<locals>.wrapper\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(fn):\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[38;5;241m.\u001b[39m_has_ops():\n\u001b[1;32m     19\u001b[0m         get_meta_lib()\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mtorchvision, op_name), overload_name), fn)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\n","\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)"],"ename":"AttributeError","evalue":"partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)","output_type":"error"}]}]}